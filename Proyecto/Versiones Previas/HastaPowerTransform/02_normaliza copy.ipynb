{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, RobustScaler\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fase = '02_normaliza'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_config.json', 'r') as file:\n",
    "    gen_config =json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------COMIENZA----------------------------------------------\n",
      "--------------------------------------------02_normaliza--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "folder = gen_config['folder']\n",
    "\n",
    "#entradas\n",
    "path_group = gen_config['path_group']\n",
    "path_prod_stats = gen_config['path_prod_stats']\n",
    "\n",
    "#salidas\n",
    "path_norm = gen_config['path_norm']\n",
    "#path_transform_stats = gen_config['path_transform_stats']\n",
    "\n",
    "#variables\n",
    "var_escalado = gen_config['var_escalado']\n",
    "var_withmean = gen_config['var_withmean']\n",
    "\n",
    "print(f\"{'COMIENZA':-^100}\")\n",
    "print(f\"{fase:-^100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pl.read_parquet(f\"{folder}/{path_group}\")\n",
    "prod_stats = pl.read_parquet(f'{folder}/{path_prod_stats}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df_norm.to_pandas()\n",
    "prod_stats = prod_stats.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_norm.groupby(['product_id', 'customer_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_standard(group):\n",
    "    scaler = StandardScaler(with_mean=var_withmean)\n",
    "    group['tn_standard'] = scaler.fit_transform(group[['tn']])\n",
    "    # Store the scaler in a dictionary with a tuple key\n",
    "    standard_scalers[(group['product_id'].iloc[0], group['customer_id'].iloc[0])] = scaler\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scalers = {}\n",
    "df_standard = grouped.apply(scale_standard)\n",
    "df_standard = df_standard.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_data = []\n",
    "for (product_id, client_id), scaler in standard_scalers.items():\n",
    "    scaler_data.append({\n",
    "        'product_id': product_id,\n",
    "        'client_id': client_id,\n",
    "        'standard_scaler_mean': scaler.mean_[0],\n",
    "        'standard_scaler_scale': scaler.scale_[0]\n",
    "    })\n",
    "\n",
    "scalers_standard_stats = pd.DataFrame(scaler_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_robust(group):\n",
    "    scaler = RobustScaler(with_centering=var_withmean)\n",
    "    group['tn_robust'] = scaler.fit_transform(group[['tn']])\n",
    "    # Store the scaler in a dictionary with a tuple key\n",
    "    robust_scalers[(group['product_id'].iloc[0], group['customer_id'].iloc[0])] = scaler\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scalers = {}\n",
    "df_robust = grouped.apply(scale_robust)\n",
    "df_robust = df_robust.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_data = []\n",
    "for (product_id, client_id), scaler in robust_scalers.items():\n",
    "    scaler_data.append({\n",
    "        'product_id': product,\n",
    "        'client_id': client,\n",
    "        'robust_scaler_center': scaler.center_[0],\n",
    "        'robust_scaler_scale': scaler.scale_[0]\n",
    "    })\n",
    "\n",
    "scalers_robust_stats = pd.DataFrame(scaler_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>tn</th>\n",
       "      <th>tn_standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>10001</td>\n",
       "      <td>201701</td>\n",
       "      <td>99.43861</td>\n",
       "      <td>0.951113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>10001</td>\n",
       "      <td>201702</td>\n",
       "      <td>198.84365</td>\n",
       "      <td>1.901905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>10001</td>\n",
       "      <td>201703</td>\n",
       "      <td>92.46537</td>\n",
       "      <td>0.884415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>10001</td>\n",
       "      <td>201704</td>\n",
       "      <td>13.29728</td>\n",
       "      <td>0.127186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>10001</td>\n",
       "      <td>201705</td>\n",
       "      <td>101.00563</td>\n",
       "      <td>0.966101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303550</th>\n",
       "      <td>21276</td>\n",
       "      <td>10550</td>\n",
       "      <td>201908</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303551</th>\n",
       "      <td>21276</td>\n",
       "      <td>10550</td>\n",
       "      <td>201909</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.675225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303552</th>\n",
       "      <td>21276</td>\n",
       "      <td>10550</td>\n",
       "      <td>201910</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303553</th>\n",
       "      <td>21276</td>\n",
       "      <td>10550</td>\n",
       "      <td>201911</td>\n",
       "      <td>0.00371</td>\n",
       "      <td>3.340115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303554</th>\n",
       "      <td>21276</td>\n",
       "      <td>10550</td>\n",
       "      <td>201912</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5303555 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         product_id  customer_id  periodo         tn  tn_standard\n",
       "0             20001        10001   201701   99.43861     0.951113\n",
       "1             20001        10001   201702  198.84365     1.901905\n",
       "2             20001        10001   201703   92.46537     0.884415\n",
       "3             20001        10001   201704   13.29728     0.127186\n",
       "4             20001        10001   201705  101.00563     0.966101\n",
       "...             ...          ...      ...        ...          ...\n",
       "5303550       21276        10550   201908    0.00000     0.000000\n",
       "5303551       21276        10550   201909    0.00075     0.675225\n",
       "5303552       21276        10550   201910    0.00000     0.000000\n",
       "5303553       21276        10550   201911    0.00371     3.340115\n",
       "5303554       21276        10550   201912    0.00000     0.000000\n",
       "\n",
       "[5303555 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = df_norm.merge(df_standard[['product_id', 'customer_id', 'tn_standard']], on=['product_id', 'customer_id', 'periodo'], how='left')\n",
    "df_norm = df_norm.merge(  df_robust[['product_id', 'customer_id', 'tn_robust']]  , on=['product_id', 'customer_id', 'periodo'], how='left')\n",
    "df_norm = pl.from_pandas(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_stats = prod_stats.merge(scalers_standard_stats, on=['product_id', 'client_id'], how='left')\n",
    "prod_stats = prod_stats.merge(scalers_robust_stats, on=['product_id', 'client_id'], how='left')\n",
    "prod_stats = pl.from_pandas(prod_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = df_scaled.groupby(['product_id', 'customer_id'])\n",
    "# df_unscaled = grouped.apply(inverse_scale_sales)\n",
    "# df_unscaled = df_unscaled.reset_index(drop=True)\n",
    "\n",
    "# df_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inverse_scale_standard(group):\n",
    "#     scaler = standard_scalers[(group['product_id'].iloc[0], group['customer_id'].iloc[0])]\n",
    "#     group['tn_inverse'] = scaler.inverse_transform(group[['tn_standard']])\n",
    "#     return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inverse_scale_robust(group):\n",
    "#     scaler = robust_scalers[(group['product_id'].iloc[0], group['customer_id'].iloc[0])]\n",
    "#     group['tn_inverse'] = scaler.inverse_transform(group[['tn_standard']])\n",
    "#     return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_scaler_from_row(row):\n",
    "#     scaler = StandardScaler(with_mean=var_withmean)\n",
    "#     scaler.mean_ = [row['scaler_mean']]\n",
    "#     scaler.scale_ = [row['scaler_scale']]\n",
    "#     scaler.var_ = [row['scaler_scale']**2]\n",
    "#     return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_stats.write_parquet(f'{folder}/{path_prod_stats}')\n",
    "df_norm.write_parquet(f'{folder}/{path_norm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------02_normaliza--------------------------------------------\n",
      "----------------------------------------------FINALIZA----------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{fase:-^100}\")\n",
    "print(f\"{'FINALIZA':-^100}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
