{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fase = '02_normaliza'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_config.json', 'r') as file:\n",
    "    gen_config =json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------COMIENZA----------------------------------------------\n",
      "--------------------------------------------02_normaliza--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "folder = gen_config['folder']\n",
    "\n",
    "#entradas\n",
    "path_group = gen_config['path_group']\n",
    "path_prod_stats = gen_config['path_prod_stats']\n",
    "\n",
    "#salidas\n",
    "path_norm = gen_config['path_norm']\n",
    "path_transform_stats = gen_config['path_transform_stats']\n",
    "\n",
    "#variables\n",
    "var_escalado = gen_config['var_escalado']\n",
    "var_withmean = gen_config['var_withmean']\n",
    "\n",
    "print(f\"{'COMIENZA':-^100}\")\n",
    "print(f\"{fase:-^100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(f\"{folder}/{path_group}\")\n",
    "prod_stats = pl.read_parquet(f'{folder}/{path_prod_stats}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en DF:['product_id', 'customer_id', 'periodo', 'tn', 'primer_periodo', 'ultimo_periodo', 'values', 'total_tn', 'min_tn', 'average_tn', 'median_tn', 'std_dev_tn', 'iqr_tn', 'max_tn']\n",
      "df_norm shape: (5_303_555, 14)\n"
     ]
    }
   ],
   "source": [
    "df_norm = df.join(prod_stats, on=['product_id', 'customer_id'], how='left', coalesce=True)\n",
    "print(f\"Columnas en DF:{df_norm.columns}\")\n",
    "print(f\"df_norm shape: ({df_norm.shape[0]:>9_d}, {df_norm.shape[1]:_d})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juguete = df_norm.filter((pl.col('product_id') == 20011) & (pl.col('customer_id') == 10001))[['product_id','customer_id', 'periodo','tn']]\n",
    "# juguete, lambda_, scale_, mean_, var_ = power_transform(juguete)\n",
    "# juguete = power_inverse_transform(juguete, lambda_, mean_, var_)\n",
    "# juguete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACA SUCEDE LA NORMALIZACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df_norm.with_columns([\n",
    "    ((pl.col(\"periodo\").cast(pl.Utf8) + \"01\").str.to_date(\"%Y%m%d\")).alias(\"periodo_dt\"),  \n",
    "])\n",
    "\n",
    "primer_periodo = df_norm['periodo_dt'].min()\n",
    "\n",
    "df_norm = df_norm.with_columns(\n",
    "    ((pl.col('periodo_dt').dt.year() - primer_periodo.year) * 12 +\n",
    "    (pl.col('periodo_dt').dt.month() - primer_periodo.month)).alias('mes_indice')\n",
    ")\n",
    "\n",
    "df_pivot = df_norm.pivot(values='tn', index=['product_id', 'customer_id'], columns='mes_indice')\n",
    "df_pivot = df_pivot.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_transform(row_df):\n",
    "    pt = PowerTransformer()\n",
    "    transformed_data = pt.fit_transform(row_df[2:].to_numpy().reshape(-1, 1)).flatten()\n",
    "    #group_df = group_df.with_columns(pl.Series('tn_trans', transformed_data))\n",
    "\n",
    "    stdscaler = pt.__getattribute__('_scaler')\n",
    "    \n",
    "    lambda_ = pt.lambdas_[0]\n",
    "    scale_ = stdscaler.scale_[0]\n",
    "    mean_ = stdscaler.mean_[0]\n",
    "    var_ = stdscaler.var_[0]\n",
    "\n",
    "    return transformed_data, lambda_, scale_, mean_, var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_inverse_transform(x_trans, lambda_, mean_, var_):\n",
    "    try:\n",
    "        x = x_trans.to_numpy().reshape(-1, 1)\n",
    "    except:\n",
    "        x = np.array(x_trans)\n",
    "\n",
    "    x = x * var_ ** 0.5 + mean_\n",
    "\n",
    "    x_inv = np.zeros_like(x)\n",
    "    pos = x >= 0\n",
    "\n",
    "    # when x >= 0\n",
    "    if abs(lambda_) < np.spacing(1.0):\n",
    "        x_inv[pos] = np.exp(x[pos]) - 1\n",
    "    else:  # lambda_ != 0\n",
    "        x_inv[pos] = np.power(x[pos] * lambda_ + 1, 1 / lambda_) - 1\n",
    "\n",
    "    # when x < 0\n",
    "    if abs(lambda_ - 2) > np.spacing(1.0):\n",
    "        x_inv[~pos] = 1 - np.power(-(2 - lambda_) * x[~pos] + 1, 1 / (2 - lambda_))\n",
    "    else:  # lambda_ == 2\n",
    "        x_inv[~pos] = 1 - np.exp(-x[~pos])\n",
    "\n",
    "    x_orig = x_inv.flatten()\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var_escalado == 'tn_trans':\n",
    "    transform_stats = pd.DataFrame(columns=['product_id', 'customer_id', 'pwr_lambda', 'pwr_scale', 'pwr_mean', 'pwr_var'])\n",
    "    df_pwr_pt = pd.DataFrame(columns=['product_id', 'customer_id', 'mes_indice', 'tn', 'tn_trans'])\n",
    "    df_pwr = pd.DataFrame(columns=['product_id', 'customer_id', 'mes_indice', 'tn', 'tn_trans'])\n",
    "    meses = pd.Series(df_pivot.columns[2:])\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in df_pivot.iterrows():\n",
    "        if i % (df_pivot.shape[0]//100) == 0:\n",
    "            #print(f\"Transformando serie {i} de {df_pivot.shape[0]}, {round(i/df_pivot.shape[0]*100, 2)}%\")\n",
    "            df_pwr = pd.concat([df_pwr, df_pwr_pt], ignore_index=True, axis=0)  \n",
    "            df_pwr_pt = pd.DataFrame(columns=['product_id', 'customer_id', 'mes_indice', 'tn', 'tn_trans'])\n",
    "            print(f\"Transformando serie {i} de {df_pivot.shape[0]}, Acumulado: {df_pwr.shape}, {round(i/df_pivot.shape[0]*100, 2)}% || {round(time.time() - start_time, 2)} segundos\")\n",
    "            start_time = time.time()\n",
    "        \n",
    "        x_trans, lambda_, scale_, mean_, var_ = power_transform(row)\n",
    "        df_row = pd.DataFrame({'product_id' : row.iloc[0],\n",
    "                                'customer_id' : row.iloc[1],\n",
    "                                'mes_indice' : meses.values,\n",
    "                                'tn' : row.iloc[2:],\n",
    "                                'tn_trans' : x_trans})\n",
    "        df_pwr_pt = pd.concat([df_pwr_pt, df_row], ignore_index=True, axis=0)    \n",
    "        \n",
    "        transform_stats_row = pd.DataFrame({'product_id': row.iloc[0],\n",
    "                            'customer_id': row.iloc[1],\n",
    "                            'pwr_lambda': lambda_,\n",
    "                            'pwr_scale': scale_,\n",
    "                            'pwr_mean': mean_,\n",
    "                            'pwr_var': var_\n",
    "                            }, index=[i])\n",
    "        transform_stats = pd.concat([transform_stats, transform_stats_row], ignore_index=True, axis=0)\n",
    "\n",
    "    #resto\n",
    "    print(f\"Transformando serie {i} de {df_pivot.shape[0]}, Acumulado: {df_pwr.shape}, {round(i/df_pivot.shape[0]*100, 2)}% || {round(time.time() - start_time, 2)} segundos\")\n",
    "    df_pwr = pd.concat([df_pwr, df_pwr_pt], ignore_index=True, axis=0)  \n",
    "    df_pwr_pt = pd.DataFrame(columns=['product_id', 'customer_id', 'mes_indice', 'tn', 'tn_trans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para controlar\n",
    "# a = df_pwr[(df_pwr['product_id'] == 20001) & (df_pwr['customer_id'] == 10001)]['tn_trans']\n",
    "# b = power_inverse_transform(a,\n",
    "#                         lambda_=transform_stats.iloc[0]['pwr_lambda'],\n",
    "#                         mean_=transform_stats.iloc[0]['pwr_mean'],\n",
    "#                         var_=transform_stats.iloc[0]['pwr_var'])\n",
    "# c = df_pwr[(df_pwr['product_id'] == 20001) & (df_pwr['customer_id'] == 10001)]['tn']\n",
    "\n",
    "# pd.DataFrame({'a': a, 'b': b, 'c': c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var_escalado == 'tn_trans':\n",
    "    df_pwr = pl.from_pandas(df_pwr)\n",
    "    transform_stats = pl.from_pandas(transform_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var_escalado == 'tn_trans':\n",
    "    df_pwr = df_pwr.with_columns([\n",
    "        pl.col('product_id').cast(pl.Int64),\n",
    "        pl.col('customer_id').cast(pl.Int64),\n",
    "        pl.col('mes_indice').cast(pl.Int32),\n",
    "    ])\n",
    "\n",
    "    transform_stats = transform_stats.with_columns([\n",
    "        pl.col('product_id').cast(pl.Int64),\n",
    "        pl.col('customer_id').cast(pl.Int64),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var_escalado == 'tn_trans':\n",
    "    df_pwr.write_parquet(f'{folder}/pwr.parquet')\n",
    "    transform_stats.write_parquet(f'{folder}/{path_transform_stats}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var_escalado == 'tn_trans':\n",
    "    df_pwr = pl.read_parquet(f'{folder}/pwr.parquet')\n",
    "    transform_stats = pl.read_parquet(f'{folder}/{path_transform_stats}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var_escalado == 'tn_trans':\n",
    "    df_norm = df_norm.join(df_pwr[['product_id', 'customer_id', 'mes_indice', 'tn_trans']],\n",
    "                on=['product_id', 'customer_id', 'mes_indice'], how='left', coalesce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp = df_norm.join(transform_stats, on=['product_id', 'customer_id'], how='left', coalesce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn_standard calculado _SIN_ MEDIA, solo DESVIO\n",
      "tn_robust calculado _SIN_ MEDIANA, solo RANGO INTERCUARTIL\n"
     ]
    }
   ],
   "source": [
    "if var_withmean:\n",
    "    print('tn_standard calculado _CON_ MEDIA Y DESVIO')\n",
    "    df_norm = df_norm.with_columns([\n",
    "        ((pl.col('tn') - pl.col('average_tn')) / pl.col('std_dev_tn')).alias('tn_standard'),\n",
    "    ])\n",
    "    print('tn_robust calculado _CON_ MEDIANA Y RANGO INTERCUARTIL')\n",
    "    df_norm = df_norm.with_columns([\n",
    "        ((pl.col('tn') - pl.col('median_tn')) / pl.col('iqr_tn')).alias('tn_robust'),\n",
    "    ])\n",
    "else:\n",
    "    print('tn_standard calculado _SIN_ MEDIA, solo DESVIO')\n",
    "    df_norm = df_norm.with_columns([\n",
    "        ((pl.col('tn')) / pl.col('std_dev_tn')).alias('tn_standard'),\n",
    "    ])\n",
    "    print('tn_robust calculado _SIN_ MEDIANA, solo RANGO INTERCUARTIL')\n",
    "    df_norm = df_norm.with_columns([\n",
    "        ((pl.col('tn')) / pl.col('iqr_tn')).alias('tn_robust'),\n",
    "    ])\n",
    "\n",
    "\n",
    "#se  pueden pasar a cero xq corrije los productos constantes\n",
    "\n",
    "df_norm = df_norm.with_columns([\n",
    "    pl.col(\"tn_standard\")\n",
    "    .fill_nan(0)\n",
    "    .replace([float('inf'), float('-inf')], 0),\n",
    "    pl.col(\"tn_robust\")\n",
    "    .fill_nan(0)\n",
    "    .replace([float('inf'), float('-inf')], 0),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df_norm.sort(by=['product_id', 'customer_id', 'periodo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metodo de escalado: tn_robust\n"
     ]
    }
   ],
   "source": [
    "#asigno la que efectivamente se usa en el resto del proceso\n",
    "df_norm = df_norm.with_columns(pl.col(var_escalado).alias('tn_norm'))\n",
    "print(f\"Metodo de escalado: {var_escalado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.write_parquet(f'{folder}/{path_norm}')\n",
    "if var_escalado == 'tn_trans':\n",
    "    transform_stats.write_parquet(f'{folder}/{path_transform_stats}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_norm completo: (5303555, 19)\n",
      "df_norm diciembre: (178684, 19)\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_norm completo: {df_norm.shape}\")\n",
    "print(f\"df_norm diciembre: {df_norm.filter(pl.col('periodo') == 201912).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>product_id</th><th>customer_id</th><th>periodo</th><th>tn</th><th>primer_periodo</th><th>ultimo_periodo</th><th>values</th><th>total_tn</th><th>min_tn</th><th>average_tn</th><th>median_tn</th><th>std_dev_tn</th><th>iqr_tn</th><th>max_tn</th><th>periodo_dt</th><th>mes_indice</th><th>tn_standard</th><th>tn_robust</th><th>tn_norm</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>date</td><td>date</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>date</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 19)\n",
       "┌────────────┬─────────────┬─────────┬─────┬───┬────────────┬─────────────┬───────────┬─────────┐\n",
       "│ product_id ┆ customer_id ┆ periodo ┆ tn  ┆ … ┆ mes_indice ┆ tn_standard ┆ tn_robust ┆ tn_norm │\n",
       "│ ---        ┆ ---         ┆ ---     ┆ --- ┆   ┆ ---        ┆ ---         ┆ ---       ┆ ---     │\n",
       "│ i64        ┆ i64         ┆ i64     ┆ f64 ┆   ┆ i32        ┆ f64         ┆ f64       ┆ f64     │\n",
       "╞════════════╪═════════════╪═════════╪═════╪═══╪════════════╪═════════════╪═══════════╪═════════╡\n",
       "└────────────┴─────────────┴─────────┴─────┴───┴────────────┴─────────────┴───────────┴─────────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.filter((pl.col('tn_standard') == np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datos con inf en tn_standard: 0.0\n",
      "Datos con -inf en tn_standard: 0.0\n",
      "Datos con NaN en tn_standard: 0.0\n",
      "Datos con inf en tn_robust: 0.0\n",
      "Datos con -inf en tn_robust: 0.0\n",
      "Datos con NaN en tn_robust: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Datos con inf en tn_standard: {df_norm.filter((pl.col('tn_standard') == np.inf))['total_tn'].sum()}\n",
    "Datos con -inf en tn_standard: {df_norm.filter((pl.col('tn_standard') == -np.inf))['total_tn'].sum()}\n",
    "Datos con NaN en tn_standard: {df_norm.filter((pl.col('tn_standard') == np.NaN))['total_tn'].sum()}\n",
    "Datos con inf en tn_robust: {df_norm.filter((pl.col('tn_robust') == np.inf))['total_tn'].sum()}\n",
    "Datos con -inf en tn_robust: {df_norm.filter((pl.col('tn_robust') == -np.inf))['total_tn'].sum()}\n",
    "Datos con NaN en tn_robust: {df_norm.filter((pl.col('tn_robust') == np.NaN))['total_tn'].sum()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df_norm.join(transform_stats, on=['product_id', 'customer_id'], how='left', coalesce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df_temp.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp['tn_inversa'] = df_temp.apply(lambda row: power_inverse_transform(row['tn_trans'], row['pwr_lambda'], row['pwr_mean'], row['pwr_var']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp['tn_inversa'] = [tn_inv[0] for tn_inv in df_temp['tn_inversa']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = df_temp['tn_inversa'] - df_temp['tn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = df_temp[np.abs(df_temp['tn_inversa'] - df_temp['tn']) >= 0.01]\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp.to_parquet(f'{folder}/temp.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------02_normaliza--------------------------------------------\n",
      "----------------------------------------------FINALIZA----------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{fase:-^100}\")\n",
    "print(f\"{'FINALIZA':-^100}\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
