{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "fase = '02b_DTW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_config.json', 'r') as file:\n",
    "    gen_config =json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = gen_config['folder']\n",
    "\n",
    "path_norm = gen_config['path_norm']\n",
    "path_dtw = gen_config['path_dtw']\n",
    "path_prod_stats = gen_config['path_prod_stats']\n",
    "\n",
    "clusters = gen_config['var_clusters']\n",
    "corte_prod_dtw = gen_config['var_corte_prod_dtw']\n",
    "leer_pickle_dtw = gen_config['var_leer_pickle_dtw']\n",
    "path_traindtw = gen_config['path_traindtw']\n",
    "path_fitdtw = gen_config['path_fitdtw']\n",
    "path_dtwmodel = gen_config['path_dtw_model']\n",
    "ejecutar_dtw = gen_config['var_ejecutar_dtw']\n",
    "dibujar_dtw = gen_config['var_dibujar_dtw']\n",
    "\n",
    "print(f\"{'COMIENZA':-^100}\")\n",
    "print(f\"{fase:-^100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.read_parquet(f\"{folder}/{path_norm}\")\n",
    "prod_stats = pd.read_parquet(f'{folder}/{path_prod_stats}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.sort_values(by=['product_id', 'customer_id','periodo'], inplace=True)\n",
    "df_train = df_norm[df_norm['product_id'] <= corte_prod_dtw]\n",
    "df_fit = df_norm[df_norm['product_id'] > corte_prod_dtw]\n",
    "\n",
    "print(f\"df_norm shape:   ({df_norm.shape[0]:>9_d},{df_norm.shape[1]:_d})\")\n",
    "print(f\"df_train shape:  ({df_train.shape[0]:>9_d},{df_train.shape[1]:_d})\")\n",
    "print(f\"df_fit shape:    ({df_fit.shape[0]:>9_d},{df_fit.shape[1]:_d})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corte_fecha_prodcust = '2019-06-01'\n",
    "minimo_values_series = 3\n",
    "\n",
    "print(f\"ProdCust presentes post {corte_fecha_prodcust} {prod_stats[prod_stats['ultimo_periodo'] >= corte_fecha_prodcust].shape}\")\n",
    "print(f\"ProdCust con mas de {minimo_values_series} datos {prod_stats[prod_stats['values'] >= minimo_values_series].shape}\")\n",
    "\n",
    "print(f\"ProdCust VALIDOS (ambas condiciones) {prod_stats[(prod_stats['ultimo_periodo'] >= corte_fecha_prodcust) & (prod_stats['values'] >= minimo_values_series)].shape}\")\n",
    "\n",
    "prodcust_validos = prod_stats[(prod_stats['ultimo_periodo'] >= corte_fecha_prodcust) & (prod_stats['values'] >= minimo_values_series)][['product_id', 'customer_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodcust_train = df_train[['product_id', 'customer_id']].drop_duplicates()\n",
    "prodcust_fit = df_fit[['product_id', 'customer_id']].drop_duplicates()\n",
    "\n",
    "print(f\"ProdCust sin filtrar:\")\n",
    "print(f\"prodcust_train series:  ({prodcust_train.shape[0]:>9_d},{df_train.shape[1]:_d})\")\n",
    "print(f\"prodcust_fit series:    ({prodcust_fit.shape[0]:>9_d},{df_fit.shape[1]:_d})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodcust_train = prodcust_train.merge(prodcust_validos, on=['product_id', 'customer_id'], how='inner')\n",
    "prodcust_fit = prodcust_fit.merge(prodcust_validos, on=['product_id', 'customer_id'], how='inner')\n",
    "\n",
    "print(f\"ProdCust aplicando filtros:\")\n",
    "print(f\"prodcust_train series:  ({prodcust_train.shape[0]:>9_d},{df_train.shape[1]:_d})\")\n",
    "print(f\"prodcust_fit series:    ({prodcust_fit.shape[0]:>9_d},{df_fit.shape[1]:_d})\")\n",
    "print(f\"Productos presentes:    {prodcust_train['product_id'].nunique() + prodcust_fit['product_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if leer_pickle_dtw:\n",
    "    print(f\"Cargando series DTW: {path_traindtw}\")\n",
    "    X_train = np.load(f\"{folder}/{path_traindtw}\")\n",
    "    print(f\"series_train shape: {X_train.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Creando series DTW: {path_traindtw}\")\n",
    "    series_train = []\n",
    "    i = 0\n",
    "    for producto, cliente in prodcust_train.values:\n",
    "        i +=1\n",
    "        print(f\"Timeseries {i} de {prodcust_train.shape[0]}: {producto}, {cliente}\", end=\"\\r\")\n",
    "        series_train.append(df_train[(df_train[\"product_id\"] == producto) & (df_train[\"customer_id\"] == cliente)][['tn_norm']])\n",
    "    \n",
    "    X_train = to_time_series_dataset(series_train)\n",
    "    np.save(f\"{folder}/{path_traindtw}\", X_train)\n",
    "    # with open('series_train.pickle', 'wb') as handle:\n",
    "    #     pickle.dump(series_train, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if leer_pickle_dtw:\n",
    "    X_fit = np.load(f\"{folder}/{path_fitdtw}\")\n",
    "    print(f\"series_fit shape: {X_fit.shape}\")\n",
    "    \n",
    "else:\n",
    "    series_fit = []\n",
    "    i = 0\n",
    "    for producto, cliente in prodcust_fit.values:\n",
    "        i +=1\n",
    "        print(f\"Timeseries {i} de {prodcust_fit.shape[0]}: {producto}, {cliente}\", end=\"\\r\")\n",
    "        series_fit.append(df_fit[(df_fit[\"product_id\"] == producto) & (df_fit[\"customer_id\"] == cliente)][['tn_norm']])\n",
    "    \n",
    "    X_fit = to_time_series_dataset(series_fit)\n",
    "    np.save(f\"{folder}/{path_fitdtw}\", X_fit)\n",
    "    # with open('series_fit.pickle', 'wb') as handle:\n",
    "    #     pickle.dump(series_fit, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(X_train, nan=0, copy=False)\n",
    "print(f\"X_train timeseries:  ({X_train.shape[0]:>9_d},{X_train.shape[1]:_d},{X_train.shape[2]:_d})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ejecutar_dtw:\n",
    "    if leer_pickle_dtw:\n",
    "        x_clusters_dtw = np.full((X_train.shape[0], len(clusters)), np.nan)\n",
    "        model_dtw = []\n",
    "        model_dtw.append(TimeSeriesKMeans.from_pickle(f\"{folder}/{path_dtwmodel}\"))\n",
    "    else:\n",
    "        x_clusters_dtw = np.full((X_train.shape[0], len(clusters)), np.nan)\n",
    "        model_dtw = []\n",
    "\n",
    "        for i in range(len(clusters)):\n",
    "            start_time = datetime.now()\n",
    "            model = TimeSeriesKMeans(n_clusters=clusters[i], metric=\"dtw\",\n",
    "                                    max_iter=50, random_state=42, max_iter_barycenter=50,\n",
    "                                    n_jobs = -1, verbose = True)\n",
    "            x_clusters_dtw[:,i] = model.fit_predict(X_train)\n",
    "            print(f\"DTW Corrida {i}, clusters: {model.n_clusters}, inertia: {model.inertia_:.2f}, time: {(datetime.now()-start_time).total_seconds():.2f}\")\n",
    "            model_dtw.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dtw_model = f\"02b_dtw_model.pkl\"\n",
    "model_dtw[0].to_pickle(f\"{folder}/{path_dtw_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ejecutar_dtw:\n",
    "    df_clusters = pd.concat([prodcust_train.reset_index(drop=True), pd.DataFrame(x_clusters_dtw)], axis=1)\n",
    "    cols = ['product_id', 'customer_id']\n",
    "    for method in ['cluster_dtw']:\n",
    "        for cluster in clusters:\n",
    "            cols.append(f\"{method}_{cluster:0>2}\")\n",
    "\n",
    "    df_clusters.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(X_fit, nan=0, copy=False)\n",
    "print(f\"X_fit timeseries:    ({X_fit.shape[0]:>9_d},{X_fit.shape[1]:_d},{X_fit.shape[2]:_d})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ejecutar_dtw:\n",
    "    x_clusters_dtw_fit = np.full((X_fit.shape[0], len(clusters)), np.nan)\n",
    "    x_clusters_dtw_fit[:,0] = model_dtw[0].predict(X_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ejecutar_dtw:\n",
    "    df_clusters_fit = pd.concat([prodcust_fit.reset_index(drop=True), pd.DataFrame(x_clusters_dtw_fit)], axis=1)\n",
    "    cols = ['product_id', 'customer_id']\n",
    "    for method in ['cluster_dtw']:\n",
    "        for cluster in clusters:\n",
    "            cols.append(f\"{method}_{cluster:0>2}\")\n",
    "\n",
    "    df_clusters_fit.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ejecutar_dtw:\n",
    "    df_clusters_full = pd.concat([df_clusters, df_clusters_fit], axis=0)\n",
    "    df_clusters_full.to_parquet(f\"{folder}/{path_dtw}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dibujar_dtw:\n",
    "    fig, axs = plt.subplots(max(clusters), len(clusters), figsize=(24, 40))\n",
    "\n",
    "    for i in range(len(clusters)):\n",
    "        y_pred = x_clusters_dtw[:,i]\n",
    "\n",
    "        for j in range(clusters[i]):\n",
    "            for xx in X_train[y_pred == j]:\n",
    "                axs[j, i].plot(xx.ravel(), \"k-\", alpha=.1)\n",
    "            axs[j, i].plot(model_dtw[i].cluster_centers_[j].ravel(), color='green')\n",
    "            axs[j, i].set_title(f\"Cluster {j} de {clusters[i]} DTW\")\n",
    "            \n",
    "            # for xx in X_train[y_pred == j]:\n",
    "            #     axs[j, (i+4)].plot(xx.ravel(), \"k-\", alpha=.1)\n",
    "            # axs[j, (i+4)].plot(model_softdtw[i].cluster_centers_[j].ravel(), color='blue')\n",
    "            # axs[j, (i+4)].set_title(f\"Cluster {j} de {clusters[i]} Soft_DTW\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{fase:-^100}\")\n",
    "print(f\"{'FINALIZA':-^100}\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
