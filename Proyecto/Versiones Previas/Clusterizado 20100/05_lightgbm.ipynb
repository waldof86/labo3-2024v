{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fase = '05_lightgbm (un intento)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_config.json', 'r') as file:\n",
    "    gen_config =json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------COMIENZA----------------------------------------------\n",
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "folder = gen_config['folder']\n",
    "\n",
    "path_pred_test = gen_config['path_pred_test']\n",
    "path_pred_futuro = gen_config['path_pred_futuro']\n",
    "path_prod_stats = gen_config['path_prod_stats']\n",
    "\n",
    "path_train = gen_config['path_train']\n",
    "path_test = gen_config['path_test']\n",
    "path_futuro = gen_config['path_futuro']\n",
    "\n",
    "lgbm_params = gen_config['var_lgbm_params']\n",
    "exclusiones = gen_config['var_exclusiones']\n",
    "dibujar_pesos = gen_config['var_dibujar_pesos']\n",
    "var_num_boost_round = gen_config['var_num_boost_round']\n",
    "clusters = gen_config['var_clusters']\n",
    "\n",
    "print(f\"{'COMIENZA':-^100}\")\n",
    "print(f\"{fase:-^100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df_train...........: (2173865, 188)\n",
      "Shape df_test............: (68823, 188)\n",
      "Shape df_futuro..........: (53008, 188)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_parquet(f\"{folder}/{path_train}\")\n",
    "df_test = pd.read_parquet(f\"{folder}/{path_test}\")\n",
    "df_futuro = pd.read_parquet(f\"{folder}/{path_futuro}\")\n",
    "\n",
    "prod_stats = pd.read_parquet(f\"{folder}/{path_prod_stats}\")\n",
    "prod_stats = prod_stats[['product_id','customer_id', 'average_tn', 'std_dev_tn', 'total_tn']]\n",
    "\n",
    "print(f\"{'Shape df_train':.<25}: {df_train.shape}\")\n",
    "print(f\"{'Shape df_test':.<25}: {df_test.shape}\")\n",
    "print(f\"{'Shape df_futuro':.<25}: {df_futuro.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos en tn_futuro de Test: 51079\n",
      "Shape df_test dropna.....: (17744, 188)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nulos en tn_futuro de Test: {df_test['tn_futuro'].isna().sum()}\")\n",
    "#df_test['tn_futuro'] = df_test['tn_futuro'].fillna(0)\n",
    "df_test.dropna(subset=['tn_futuro'], inplace=True)\n",
    "print(f\"{'Shape df_test dropna':.<25}: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRIBUCION DE DATOS EN CLUSTERS:\n",
      "          train  train_prop  test  test_prop  futuro  futuro_prop\n",
      "cluster                                                          \n",
      "0         37249    0.020453   212   0.011948    1107     0.022224\n",
      "1         53173    0.029197   951   0.053596    1360     0.027304\n",
      "2         68091    0.037388   494   0.027840    1580     0.031721\n",
      "3         64951    0.035664   428   0.024121    3328     0.066814\n",
      "4         67994    0.037335   652   0.036745    1488     0.029874\n",
      "5         56078    0.030792   654   0.036858    1354     0.027183\n",
      "6         60497    0.033218   381   0.021472    1425     0.028609\n",
      "7         77331    0.042461   303   0.017076    1738     0.034893\n",
      "8         50010    0.027460   979   0.055174    1318     0.026461\n",
      "9         54030    0.029667   388   0.021867    2242     0.045011\n",
      "10        51275    0.028154   505   0.028460    1094     0.021963\n",
      "11        60401    0.033165   298   0.016794    1331     0.026722\n",
      "12       113816    0.062495   793   0.044691    4725     0.094860\n",
      "13        84282    0.046278   571   0.032180    2332     0.046818\n",
      "14        61315    0.033667   723   0.040746    1461     0.029331\n",
      "15        84774    0.046548   553   0.031165    2050     0.041156\n",
      "16        85059    0.046705   378   0.021303    2200     0.044168\n",
      "17        35304    0.019385   503   0.028348     791     0.015880\n",
      "18        50611    0.027790   590   0.033251    2068     0.041518\n",
      "19        24751    0.013590   464   0.026150     606     0.012166\n",
      "20        50071    0.027493   699   0.039394    1174     0.023570\n",
      "21        68530    0.037629   778   0.043846    1949     0.039129\n",
      "22        48094    0.026408   919   0.051792    1206     0.024212\n",
      "23        16429    0.009021   465   0.026206     476     0.009556\n",
      "24        59797    0.032834   607   0.034209    1307     0.026240\n",
      "25        85968    0.047204   378   0.021303    2028     0.040715\n",
      "26        66534    0.036533  1153   0.064980    1653     0.033186\n",
      "27        80095    0.043979  1214   0.068417    1931     0.038767\n",
      "28        41130    0.022584   365   0.020570     868     0.017426\n",
      "29        63569    0.034905   346   0.019500    1620     0.032524\n"
     ]
    }
   ],
   "source": [
    "distribution_report = pd.DataFrame(range(0,clusters[0]), columns=['cluster'])\n",
    "distribution_report['train'] = df_train[[f'cluster_dtw_{clusters[0]}','periodo']].groupby(f'cluster_dtw_{clusters[0]}').count()\n",
    "distribution_report['train_prop'] = distribution_report['train'] / distribution_report['train'].sum()\n",
    "distribution_report['test'] = df_test[[f'cluster_dtw_{clusters[0]}','periodo']].groupby(f'cluster_dtw_{clusters[0]}').count()\n",
    "distribution_report['test_prop'] = distribution_report['test'] / distribution_report['test'].sum()\n",
    "distribution_report['futuro'] = df_futuro[[f'cluster_dtw_{clusters[0]}','periodo']].groupby(f'cluster_dtw_{clusters[0]}').count()\n",
    "distribution_report['futuro_prop'] = distribution_report['futuro'] / distribution_report['futuro'].sum()\n",
    "distribution_report.set_index('cluster', inplace=True)\n",
    "\n",
    "print(f\"DISTRIBUCION DE DATOS EN CLUSTERS:\\n{distribution_report.head(clusters[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertidas a categorical: ['yearquarter', 'cat1', 'cat2', 'cat3', 'brand', 'descripcion', 'cluster_dtw_30']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df_train.select_dtypes(['category']).columns.tolist()\n",
    "for col in categorical_features:\n",
    "    df_train[col] = df_train[col].cat.codes\n",
    "    df_test[col] = df_test[col].cat.codes\n",
    "    df_futuro[col] = df_futuro[col].cat.codes\n",
    "print(f\"Convertidas a categorical: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_cluster_ttf(df_train, df_test, df_futuro, cluster_col, cluster):\n",
    "    X_train = df_train[df_train[cluster_col] == cluster].iloc[:,:-1]\n",
    "    X_test = df_test[df_test[cluster_col] == cluster].iloc[:,:-1]\n",
    "    X_futuro = df_futuro[df_futuro[cluster_col] == cluster].iloc[:,:-1]\n",
    "\n",
    "    y_train = df_train[df_train[cluster_col] == cluster].iloc[:,-1]\n",
    "    y_test = df_test[df_test[cluster_col] == cluster].iloc[:,-1]\n",
    "    y_futuro = df_futuro[df_futuro[cluster_col] == cluster].iloc[:,-1]\n",
    "\n",
    "    print(f\"{'Cluster Column':.<25}: {cluster_col}\")\n",
    "    print(f\"{'Cluster':.<25}: {cluster}\")\n",
    "    print(f\"{'Shape X_train':.<25}: {X_train.shape}\")\n",
    "    print(f\"{'Shape X_test':.<25}: {X_test.shape}\")\n",
    "    print(f\"{'Shape X_futuro':.<25}: {X_futuro.shape}\")\n",
    "\n",
    "    print(f\"{'Shape y_train':.<25}: {y_train.shape}\")\n",
    "    print(f\"{'Shape y_test':.<25}: {y_test.shape}\")\n",
    "    print(f\"{'Shape y_futuro':.<25}: {y_futuro.shape}\")\n",
    "    print(f\"\\n\")\n",
    "\n",
    "    return X_train, X_test, X_futuro, y_train, y_test, y_futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster(X_train, X_test, X_futuro, y_train, y_test, y_futuro):\n",
    "\n",
    "    train_data = lgb.Dataset(X_train.drop(columns=exclusiones), label=y_train)\n",
    "    test_data = lgb.Dataset(X_test.drop(columns=exclusiones), label=y_test)\n",
    "    #futuro_data = lgb.Dataset(X_futuro.drop(columns=exclusiones), label=y_futuro)\n",
    "\n",
    "    params = lgbm_params\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=var_num_boost_round,\n",
    "                    valid_sets=[train_data, test_data],\n",
    "                    )\n",
    "\n",
    "    y_pred = model.predict(X_test.drop(columns=exclusiones), num_iteration=model.best_iteration)\n",
    "    y_pred_futuro = model.predict(X_futuro.drop(columns=exclusiones), num_iteration=model.best_iteration)\n",
    "\n",
    "    return model, y_pred, y_pred_futuro\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 0\n",
      "Shape X_train............: (37249, 187)\n",
      "Shape X_test.............: (212, 187)\n",
      "Shape X_futuro...........: (1107, 187)\n",
      "Shape y_train............: (37249,)\n",
      "Shape y_test.............: (212,)\n",
      "Shape y_futuro...........: (1107,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 75012\n",
      "[LightGBM] [Info] Number of data points in the train set: 37249, number of used features: 159\n",
      "[LightGBM] [Info] Start training from score -0.132066\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[827]\ttraining's l2: 0.0191214\ttraining's rmse: 0.13828\tvalid_1's l2: 0.00877517\tvalid_1's rmse: 0.0936759\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 1\n",
      "Shape X_train............: (53173, 187)\n",
      "Shape X_test.............: (951, 187)\n",
      "Shape X_futuro...........: (1360, 187)\n",
      "Shape y_train............: (53173,)\n",
      "Shape y_test.............: (951,)\n",
      "Shape y_futuro...........: (1360,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 98224\n",
      "[LightGBM] [Info] Number of data points in the train set: 53173, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -0.082439\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4548]\ttraining's l2: 1.3048e-07\ttraining's rmse: 0.00036122\tvalid_1's l2: 5.66658e-08\tvalid_1's rmse: 0.000238046\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 2\n",
      "Shape X_train............: (68091, 187)\n",
      "Shape X_test.............: (494, 187)\n",
      "Shape X_futuro...........: (1580, 187)\n",
      "Shape y_train............: (68091,)\n",
      "Shape y_test.............: (494,)\n",
      "Shape y_futuro...........: (1580,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 93632\n",
      "[LightGBM] [Info] Number of data points in the train set: 68091, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score -0.032581\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[727]\ttraining's l2: 0.0935588\ttraining's rmse: 0.305874\tvalid_1's l2: 0.0369594\tvalid_1's rmse: 0.192248\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 3\n",
      "Shape X_train............: (64951, 187)\n",
      "Shape X_test.............: (428, 187)\n",
      "Shape X_futuro...........: (3328, 187)\n",
      "Shape y_train............: (64951,)\n",
      "Shape y_test.............: (428,)\n",
      "Shape y_futuro...........: (3328,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 59210\n",
      "[LightGBM] [Info] Number of data points in the train set: 64951, number of used features: 149\n",
      "[LightGBM] [Info] Start training from score -0.301084\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1487]\ttraining's l2: 0.00610518\ttraining's rmse: 0.0781356\tvalid_1's l2: 0.00498489\tvalid_1's rmse: 0.0706037\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 4\n",
      "Shape X_train............: (67994, 187)\n",
      "Shape X_test.............: (652, 187)\n",
      "Shape X_futuro...........: (1488, 187)\n",
      "Shape y_train............: (67994,)\n",
      "Shape y_test.............: (652,)\n",
      "Shape y_futuro...........: (1488,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 97439\n",
      "[LightGBM] [Info] Number of data points in the train set: 67994, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score 0.014002\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1009]\ttraining's l2: 0.0430464\ttraining's rmse: 0.207476\tvalid_1's l2: 0.0167433\tvalid_1's rmse: 0.129396\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 5\n",
      "Shape X_train............: (56078, 187)\n",
      "Shape X_test.............: (654, 187)\n",
      "Shape X_futuro...........: (1354, 187)\n",
      "Shape y_train............: (56078,)\n",
      "Shape y_test.............: (654,)\n",
      "Shape y_futuro...........: (1354,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 97117\n",
      "[LightGBM] [Info] Number of data points in the train set: 56078, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -0.075816\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3066]\ttraining's l2: 4.62777e-05\ttraining's rmse: 0.00680277\tvalid_1's l2: 1.5781e-05\tvalid_1's rmse: 0.00397253\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 6\n",
      "Shape X_train............: (60497, 187)\n",
      "Shape X_test.............: (381, 187)\n",
      "Shape X_futuro...........: (1425, 187)\n",
      "Shape y_train............: (60497,)\n",
      "Shape y_test.............: (381,)\n",
      "Shape y_futuro...........: (1425,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 92661\n",
      "[LightGBM] [Info] Number of data points in the train set: 60497, number of used features: 174\n",
      "[LightGBM] [Info] Start training from score -0.076387\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[537]\ttraining's l2: 0.149384\ttraining's rmse: 0.386503\tvalid_1's l2: 0.0699055\tvalid_1's rmse: 0.264396\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 7\n",
      "Shape X_train............: (77331, 187)\n",
      "Shape X_test.............: (303, 187)\n",
      "Shape X_futuro...........: (1738, 187)\n",
      "Shape y_train............: (77331,)\n",
      "Shape y_test.............: (303,)\n",
      "Shape y_futuro...........: (1738,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 88620\n",
      "[LightGBM] [Info] Number of data points in the train set: 77331, number of used features: 173\n",
      "[LightGBM] [Info] Start training from score 0.046173\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[853]\ttraining's l2: 0.102673\ttraining's rmse: 0.320427\tvalid_1's l2: 0.0454\tvalid_1's rmse: 0.213073\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 8\n",
      "Shape X_train............: (50010, 187)\n",
      "Shape X_test.............: (979, 187)\n",
      "Shape X_futuro...........: (1318, 187)\n",
      "Shape y_train............: (50010,)\n",
      "Shape y_test.............: (979,)\n",
      "Shape y_futuro...........: (1318,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 98847\n",
      "[LightGBM] [Info] Number of data points in the train set: 50010, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score -0.083100\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l2: 1.07947e-08\ttraining's rmse: 0.000103898\tvalid_1's l2: 4.69422e-09\tvalid_1's rmse: 6.85144e-05\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 9\n",
      "Shape X_train............: (54030, 187)\n",
      "Shape X_test.............: (388, 187)\n",
      "Shape X_futuro...........: (2242, 187)\n",
      "Shape y_train............: (54030,)\n",
      "Shape y_test.............: (388,)\n",
      "Shape y_futuro...........: (2242,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 68632\n",
      "[LightGBM] [Info] Number of data points in the train set: 54030, number of used features: 152\n",
      "[LightGBM] [Info] Start training from score 0.250426\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1031]\ttraining's l2: 0.0175862\ttraining's rmse: 0.132613\tvalid_1's l2: 0.0114948\tvalid_1's rmse: 0.107214\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 10\n",
      "Shape X_train............: (51275, 187)\n",
      "Shape X_test.............: (505, 187)\n",
      "Shape X_futuro...........: (1094, 187)\n",
      "Shape y_train............: (51275,)\n",
      "Shape y_test.............: (505,)\n",
      "Shape y_futuro...........: (1094,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 96559\n",
      "[LightGBM] [Info] Number of data points in the train set: 51275, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score 0.061401\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1278]\ttraining's l2: 0.0074039\ttraining's rmse: 0.0860459\tvalid_1's l2: 0.00234778\tvalid_1's rmse: 0.0484539\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 11\n",
      "Shape X_train............: (60401, 187)\n",
      "Shape X_test.............: (298, 187)\n",
      "Shape X_futuro...........: (1331, 187)\n",
      "Shape y_train............: (60401,)\n",
      "Shape y_test.............: (298,)\n",
      "Shape y_futuro...........: (1331,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 89439\n",
      "[LightGBM] [Info] Number of data points in the train set: 60401, number of used features: 170\n",
      "[LightGBM] [Info] Start training from score 0.084738\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's l2: 0.452657\ttraining's rmse: 0.672798\tvalid_1's l2: 0.32805\tvalid_1's rmse: 0.572757\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 12\n",
      "Shape X_train............: (113816, 187)\n",
      "Shape X_test.............: (793, 187)\n",
      "Shape X_futuro...........: (4725, 187)\n",
      "Shape y_train............: (113816,)\n",
      "Shape y_test.............: (793,)\n",
      "Shape y_futuro...........: (4725,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 74935\n",
      "[LightGBM] [Info] Number of data points in the train set: 113816, number of used features: 159\n",
      "[LightGBM] [Info] Start training from score 0.147647\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3410]\ttraining's l2: 0.0045725\ttraining's rmse: 0.0676203\tvalid_1's l2: 0.00232746\tvalid_1's rmse: 0.0482437\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 13\n",
      "Shape X_train............: (84282, 187)\n",
      "Shape X_test.............: (571, 187)\n",
      "Shape X_futuro...........: (2332, 187)\n",
      "Shape y_train............: (84282,)\n",
      "Shape y_test.............: (571,)\n",
      "Shape y_futuro...........: (2332,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 88976\n",
      "[LightGBM] [Info] Number of data points in the train set: 84282, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -0.163923\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\ttraining's l2: 0.363867\ttraining's rmse: 0.603214\tvalid_1's l2: 0.181647\tvalid_1's rmse: 0.426201\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 14\n",
      "Shape X_train............: (61315, 187)\n",
      "Shape X_test.............: (723, 187)\n",
      "Shape X_futuro...........: (1461, 187)\n",
      "Shape y_train............: (61315,)\n",
      "Shape y_test.............: (723,)\n",
      "Shape y_futuro...........: (1461,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 97416\n",
      "[LightGBM] [Info] Number of data points in the train set: 61315, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score -0.050697\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1556]\ttraining's l2: 0.00614974\ttraining's rmse: 0.0784203\tvalid_1's l2: 0.0027183\tvalid_1's rmse: 0.0521373\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 15\n",
      "Shape X_train............: (84774, 187)\n",
      "Shape X_test.............: (553, 187)\n",
      "Shape X_futuro...........: (2050, 187)\n",
      "Shape y_train............: (84774,)\n",
      "Shape y_test.............: (553,)\n",
      "Shape y_futuro...........: (2050,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 94722\n",
      "[LightGBM] [Info] Number of data points in the train set: 84774, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score 0.021950\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1048]\ttraining's l2: 0.0569958\ttraining's rmse: 0.238738\tvalid_1's l2: 0.0235046\tvalid_1's rmse: 0.153312\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 16\n",
      "Shape X_train............: (85059, 187)\n",
      "Shape X_test.............: (378, 187)\n",
      "Shape X_futuro...........: (2200, 187)\n",
      "Shape y_train............: (85059,)\n",
      "Shape y_test.............: (378,)\n",
      "Shape y_futuro...........: (2200,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 85915\n",
      "[LightGBM] [Info] Number of data points in the train set: 85059, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score 0.079687\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1792]\ttraining's l2: 0.0187487\ttraining's rmse: 0.136926\tvalid_1's l2: 0.00873591\tvalid_1's rmse: 0.0934661\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 17\n",
      "Shape X_train............: (35304, 187)\n",
      "Shape X_test.............: (503, 187)\n",
      "Shape X_futuro...........: (791, 187)\n",
      "Shape y_train............: (35304,)\n",
      "Shape y_test.............: (503,)\n",
      "Shape y_futuro...........: (791,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 97538\n",
      "[LightGBM] [Info] Number of data points in the train set: 35304, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score 0.057521\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l2: 1.05695e-11\ttraining's rmse: 3.25108e-06\tvalid_1's l2: 3.84722e-12\tvalid_1's rmse: 1.96143e-06\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 18\n",
      "Shape X_train............: (50611, 187)\n",
      "Shape X_test.............: (590, 187)\n",
      "Shape X_futuro...........: (2068, 187)\n",
      "Shape y_train............: (50611,)\n",
      "Shape y_test.............: (590,)\n",
      "Shape y_futuro...........: (2068,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 78484\n",
      "[LightGBM] [Info] Number of data points in the train set: 50611, number of used features: 166\n",
      "[LightGBM] [Info] Start training from score -0.408156\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1096]\ttraining's l2: 0.00486544\ttraining's rmse: 0.0697527\tvalid_1's l2: 0.00317174\tvalid_1's rmse: 0.0563182\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 19\n",
      "Shape X_train............: (24751, 187)\n",
      "Shape X_test.............: (464, 187)\n",
      "Shape X_futuro...........: (606, 187)\n",
      "Shape y_train............: (24751,)\n",
      "Shape y_test.............: (464,)\n",
      "Shape y_futuro...........: (606,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 97318\n",
      "[LightGBM] [Info] Number of data points in the train set: 24751, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score 0.041156\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2076]\ttraining's l2: 2.26766e-07\ttraining's rmse: 0.000476199\tvalid_1's l2: 6.81041e-08\tvalid_1's rmse: 0.000260968\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 20\n",
      "Shape X_train............: (50071, 187)\n",
      "Shape X_test.............: (699, 187)\n",
      "Shape X_futuro...........: (1174, 187)\n",
      "Shape y_train............: (50071,)\n",
      "Shape y_test.............: (699,)\n",
      "Shape y_futuro...........: (1174,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 97526\n",
      "[LightGBM] [Info] Number of data points in the train set: 50071, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score 0.007503\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[448]\ttraining's l2: 0.120197\ttraining's rmse: 0.346694\tvalid_1's l2: 0.0465071\tvalid_1's rmse: 0.215655\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 21\n",
      "Shape X_train............: (68530, 187)\n",
      "Shape X_test.............: (778, 187)\n",
      "Shape X_futuro...........: (1949, 187)\n",
      "Shape y_train............: (68530,)\n",
      "Shape y_test.............: (778,)\n",
      "Shape y_futuro...........: (1949,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 95446\n",
      "[LightGBM] [Info] Number of data points in the train set: 68530, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -0.219670\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1331]\ttraining's l2: 0.00974015\ttraining's rmse: 0.0986922\tvalid_1's l2: 0.00470074\tvalid_1's rmse: 0.068562\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 22\n",
      "Shape X_train............: (48094, 187)\n",
      "Shape X_test.............: (919, 187)\n",
      "Shape X_futuro...........: (1206, 187)\n",
      "Shape y_train............: (48094,)\n",
      "Shape y_test.............: (919,)\n",
      "Shape y_futuro...........: (1206,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 98579\n",
      "[LightGBM] [Info] Number of data points in the train set: 48094, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -0.004989\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4120]\ttraining's l2: 1.43331e-07\ttraining's rmse: 0.00037859\tvalid_1's l2: 4.49008e-08\tvalid_1's rmse: 0.000211898\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 23\n",
      "Shape X_train............: (16429, 187)\n",
      "Shape X_test.............: (465, 187)\n",
      "Shape X_futuro...........: (476, 187)\n",
      "Shape y_train............: (16429,)\n",
      "Shape y_test.............: (465,)\n",
      "Shape y_futuro...........: (476,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 98141\n",
      "[LightGBM] [Info] Number of data points in the train set: 16429, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score -0.032350\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4999]\ttraining's l2: 1.69311e-23\ttraining's rmse: 4.11474e-12\tvalid_1's l2: 5.14921e-24\tvalid_1's rmse: 2.26919e-12\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 24\n",
      "Shape X_train............: (59797, 187)\n",
      "Shape X_test.............: (607, 187)\n",
      "Shape X_futuro...........: (1307, 187)\n",
      "Shape y_train............: (59797,)\n",
      "Shape y_test.............: (607,)\n",
      "Shape y_futuro...........: (1307,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 97587\n",
      "[LightGBM] [Info] Number of data points in the train set: 59797, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score 0.089449\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2111]\ttraining's l2: 0.00073783\ttraining's rmse: 0.027163\tvalid_1's l2: 0.000274919\tvalid_1's rmse: 0.0165807\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 25\n",
      "Shape X_train............: (85968, 187)\n",
      "Shape X_test.............: (378, 187)\n",
      "Shape X_futuro...........: (2028, 187)\n",
      "Shape y_train............: (85968,)\n",
      "Shape y_test.............: (378,)\n",
      "Shape y_futuro...........: (2028,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 88410\n",
      "[LightGBM] [Info] Number of data points in the train set: 85968, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score 0.108710\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1463]\ttraining's l2: 0.0318233\ttraining's rmse: 0.178391\tvalid_1's l2: 0.0121673\tvalid_1's rmse: 0.110305\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 26\n",
      "Shape X_train............: (66534, 187)\n",
      "Shape X_test.............: (1153, 187)\n",
      "Shape X_futuro...........: (1653, 187)\n",
      "Shape y_train............: (66534,)\n",
      "Shape y_test.............: (1153,)\n",
      "Shape y_futuro...........: (1653,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 99578\n",
      "[LightGBM] [Info] Number of data points in the train set: 66534, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score -0.003785\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4373]\ttraining's l2: 3.38624e-06\ttraining's rmse: 0.00184017\tvalid_1's l2: 1.15421e-06\tvalid_1's rmse: 0.00107434\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 27\n",
      "Shape X_train............: (80095, 187)\n",
      "Shape X_test.............: (1214, 187)\n",
      "Shape X_futuro...........: (1931, 187)\n",
      "Shape y_train............: (80095,)\n",
      "Shape y_test.............: (1214,)\n",
      "Shape y_futuro...........: (1931,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 98494\n",
      "[LightGBM] [Info] Number of data points in the train set: 80095, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -0.018804\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's l2: 6.33136e-06\ttraining's rmse: 0.00251622\tvalid_1's l2: 2.39295e-06\tvalid_1's rmse: 0.00154692\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 28\n",
      "Shape X_train............: (41130, 187)\n",
      "Shape X_test.............: (365, 187)\n",
      "Shape X_futuro...........: (868, 187)\n",
      "Shape y_train............: (41130,)\n",
      "Shape y_test.............: (365,)\n",
      "Shape y_futuro...........: (868,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 95871\n",
      "[LightGBM] [Info] Number of data points in the train set: 41130, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score 0.051241\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1973]\ttraining's l2: 0.000149144\ttraining's rmse: 0.0122125\tvalid_1's l2: 4.85579e-05\tvalid_1's rmse: 0.00696835\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 29\n",
      "Shape X_train............: (63569, 187)\n",
      "Shape X_test.............: (346, 187)\n",
      "Shape X_futuro...........: (1620, 187)\n",
      "Shape y_train............: (63569,)\n",
      "Shape y_test.............: (346,)\n",
      "Shape y_futuro...........: (1620,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 88948\n",
      "[LightGBM] [Info] Number of data points in the train set: 63569, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -0.163639\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[873]\ttraining's l2: 0.0432452\ttraining's rmse: 0.207955\tvalid_1's l2: 0.0182772\tvalid_1's rmse: 0.135193\n"
     ]
    }
   ],
   "source": [
    "modelos = []\n",
    "pred_final = pd.DataFrame()\n",
    "pred_final_futuro = pd.DataFrame()\n",
    "\n",
    "for cluster in range(0,clusters[0]):\n",
    "    X_train, X_test, X_futuro, y_train, y_test, y_futuro = separar_cluster_ttf(df_train, df_test, df_futuro, f'cluster_dtw_{clusters[0]}', cluster)\n",
    "    model, y_pred, y_pred_futuro = train_cluster(X_train, X_test, X_futuro, y_train, y_test, y_futuro)\n",
    "\n",
    "    modelos.append(model)\n",
    "\n",
    "    pred = X_test[['periodo','product_id','customer_id','tn_norm']]\n",
    "    pred['cluster'] = cluster\n",
    "    pred['tn_futuro'] = y_test\n",
    "    pred['tn_prediccion'] = y_pred\n",
    "    pred_final = pd.concat([pred_final, pred], ignore_index=True, axis=0)\n",
    "\n",
    "    pred_futuro =X_futuro[['periodo','product_id','customer_id','tn_norm']]\n",
    "    pred_futuro['cluster'] = cluster\n",
    "    pred_futuro['tn_futuro'] = y_futuro\n",
    "    pred_futuro['tn_prediccion'] = y_pred_futuro\n",
    "    pred_final_futuro = pd.concat([pred_final_futuro, pred_futuro], ignore_index=True, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pred_final.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "final['tn_futuro_real'] = (final['tn_norm'] + final['tn_futuro']) * final['std_dev_tn'] + final['average_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "final['tn_prediccion_real'] = (final['tn_norm'] + final['tn_prediccion']) * final['std_dev_tn'] + final['average_tn']\n",
    "final.to_parquet(f'{folder}/{path_pred_test}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_futuro = pred_final_futuro.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "final_futuro['tn_futuro_real'] = (final_futuro['tn_norm'] + final_futuro['tn_futuro']) * final_futuro['std_dev_tn'] + final_futuro['average_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "final_futuro['tn_prediccion_real'] = (final_futuro['tn_norm'] + final_futuro['tn_prediccion']) * final_futuro['std_dev_tn'] + final_futuro['average_tn']\n",
    "final_futuro.to_parquet(f'{folder}/{path_pred_futuro}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estado_control = f\"05_lightgbm Terminado - {nombrefile} - {datetime.now()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb.plot_importance(model, max_num_features=20, figsize=(10,10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_df = (\n",
    "#     pd.DataFrame({\n",
    "#         'feature_name': model.feature_name(),\n",
    "#         'importance_gain': model.feature_importance(importance_type='gain'),\n",
    "#         'importance_split': model.feature_importance(importance_type='split'),\n",
    "#     })\n",
    "#     .sort_values('importance_gain', ascending=False)\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "# importance_df.sort_values('importance_split', ascending=False, inplace=True)\n",
    "# feat_dibujar = importance_df[0:20]['feature_name'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dibujar_pesos==True:\n",
    "    fig, axs = plt.subplots(5, 4, figsize=(20, 25))\n",
    "    d = -1\n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            d+=1\n",
    "            lgb.plot_split_value_histogram(model,\n",
    "                            feature=feat_dibujar[d],\n",
    "                            bins=\"auto\",\n",
    "                            ax=axs[j, i]\n",
    "                            ,title=f\"Feat: {feat_dibujar[d]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n",
      "----------------------------------------------FINALIZA----------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{fase:-^100}\")\n",
    "print(f\"{'FINALIZA':-^100}\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
