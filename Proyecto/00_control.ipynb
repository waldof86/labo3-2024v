{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendientes\n",
    "\n",
    "* HECHO - convertir control en diccionario\n",
    "* script mas complejo para proporcion\n",
    "    - puede haber nulos, solucionar los faltantes\n",
    "    - poder darle una lista de meses\n",
    "* HECHO - arreglar scripts para control\n",
    "* reescribir optimizacion de hiperparam\n",
    "* arreglar teste de perdida al final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos:\n",
    "Luego del original, sell_in q es el source con millones de datos\n",
    "\n",
    "- \"group\": solo numero de grupo, periodo, y tb. Punto de partida para las predicciones\n",
    "- \"prod_stats\": identificador por grupo, media, maximos, minimos y otras estadisticas\n",
    "- \"prod_data_group\": informacion sobre los productos, agrupado nivel grupo (groupby cats, descripcion etc)\n",
    "- \"prod_data_ungroup\": informacion sobre los productos original, intacto del source\n",
    "- \"stock_data\": info de stocks, intacto del source\n",
    "- \"norm\": la informacion de \"group\" normalizada por media y desvio, columna tn_norm\n",
    "- \"lag\": sigue luego de norm, mismas filas pero incorporando todo el feature engineering (no solo lags)\n",
    "- \"train\": set de datos para train a partir de \"lag\" con los meses segun config\n",
    "- \"test\": set de datos para test a partir de \"lag\" con los meses segun config\n",
    "- \"futuro\": set de datos para futuro a partir de \"lag\" con los meses segun config\n",
    "- \"pred_test\": predicciones de test, con algunas columnas accesorias\n",
    "- \"pred_futuro\": predicciones de futuro, con algunas columnas accesorias\n",
    "- \"kaggle\": prediccion en formato kaggle para el submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejecutar_scripts = {\n",
    "    '01_LecturaDatos' : False,\n",
    "    '02_normaliza': False,\n",
    "    '02b_DTW' : False,\n",
    "    '03_features' : False,\n",
    "    '04_crear_train_set' : False,\n",
    "    '05_lightgbm' : True,\n",
    "    '06_evaluar_prediccion' : True\t\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOMBRE_EXPERIMENTO = '2024-06-27_NivelProducto'\n",
    "FOLDER = f'./Experimentos/{NOMBRE_EXPERIMENTO}/'\n",
    "\n",
    "dibujar_pesos = False\n",
    "lgbm_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': ['l2', 'rmse'],\n",
    "    'boosting_type': 'gbdt',\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 1,\n",
    "    'num_leaves': 40,\n",
    "    'max_depth': -1,\n",
    "    #'n_estimators': 50, \n",
    "    'feature_fraction': 0.9,\n",
    "    'max_bin': 1023,\n",
    "    'learning_rate': 0.25,\n",
    "    'force_col_wise' : True,\n",
    "    'num_threads' : 8,\n",
    "    'verbose' : 1,\n",
    "    'early_stopping_rounds' : 10\n",
    "}\n",
    "\n",
    "gen_config = {\n",
    "    \"nombre_exp\" : NOMBRE_EXPERIMENTO,\n",
    "    \"folder\" : FOLDER,\n",
    "    \"path_group\" : \"01_group.parquet\",\n",
    "    \"path_prod_stats\" : \"01_prod_stats.parquet\",\n",
    "    \"path_prod_data\" : \"01_prod_data.parquet\",\n",
    "    \"path_stock_data\" : \"01_stock_data.parquet\",\n",
    "    \"path_norm\" : \"02_norm.parquet\",\n",
    "    \"path_dtw\" : \"02b_dtw.parquet\",\n",
    "    \"path_traindtw\" : \"02b_traindtw.npy\",\n",
    "    \"path_fitdtw\" : \"02b_fitdtw.npy\",\n",
    "    \"path_dtw_model\" : \"02b_dtw_model.pkl\",\n",
    "    \"path_lag\" : \"03_lag.parquet\",\n",
    "    \"path_train\" : \"04_train.parquet\",\n",
    "    \"path_test\" : \"04_test.parquet\",\n",
    "    \"path_futuro\" : \"04_futuro.parquet\",\n",
    "    \"path_pred_test\" : \"05_pred_test.parquet\",\n",
    "    \"path_pred_futuro\" : \"05_pred_futuro.parquet\",\n",
    "    \"path_kaggle\" : f\"kaggle_{NOMBRE_EXPERIMENTO}.csv\",\n",
    "\n",
    "    #\"var_periodo_rep_start\" : 201912,\n",
    "    #\"var_periodo_rep_end\" : 201912,\n",
    "    \"var_ejecutar_dtw\": True,\n",
    "    \"var_clusters\": [10],\n",
    "    \"var_dibujar_dtw\": False, #no poner true si no se rehacen los modelos\n",
    "    \"var_corte_prod_dtw\" : 20100,\n",
    "    \"var_leer_pickle_dtw\" : True,\n",
    "    \"var_lags\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 18, 21, 24, 30, 36],\n",
    "    \"var_cates_feat\" : ['cat1', 'cat2', 'brand', 'descripcion'],\n",
    "    \"var_exclusiones\" : [],\n",
    "\n",
    "    \"var_periodo_train_start\" : 201701,\n",
    "    \"var_periodo_train_end\" : 201910,\n",
    "    \"var_periodo_test\" : 201910,\n",
    "    \"var_periodo_futuro\" : 201912,\n",
    "\n",
    "    \"var_num_boost_round\": 5000,\n",
    "    \"var_lgbm_params\" : lgbm_params,\n",
    "    \"var_dibujar_pesos\" : dibujar_pesos,\n",
    "}\n",
    "\n",
    "with open('gen_config.json', 'w') as file:\n",
    "    json.dump(gen_config, file, indent=4)\n",
    "\n",
    "if not os.path.exists(FOLDER):\n",
    "    os.makedirs(FOLDER)\n",
    "with open(f'{FOLDER}\\gen_config.json', 'w') as file:\n",
    "    json.dump(gen_config, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................Experimento.......................................................\n",
      "------------------------------------------------2024-06-27_NivelProducto------------------------------------------------\n",
      "CARPETA..................: ./Experimentos/2024-06-27_NivelProducto/\n",
      "path_group...............: 01_group.parquet ( ./Experimentos/2024-06-27_NivelProducto/01_group.parquet )\n",
      "path_prod_stats..........: 01_prod_stats.parquet ( ./Experimentos/2024-06-27_NivelProducto/01_prod_stats.parquet )\n",
      "path_prod_data...........: 01_prod_data.parquet ( ./Experimentos/2024-06-27_NivelProducto/01_prod_data.parquet )\n",
      "path_stock_data..........: 01_stock_data.parquet ( ./Experimentos/2024-06-27_NivelProducto/01_stock_data.parquet )\n",
      "path_norm................: 02_norm.parquet ( ./Experimentos/2024-06-27_NivelProducto/02_norm.parquet )\n",
      "path_dtw.................: 02b_dtw.parquet ( ./Experimentos/2024-06-27_NivelProducto/02b_dtw.parquet )\n",
      "path_traindtw............: 02b_traindtw.npy ( ./Experimentos/2024-06-27_NivelProducto/02b_traindtw.npy )\n",
      "path_fitdtw..............: 02b_fitdtw.npy ( ./Experimentos/2024-06-27_NivelProducto/02b_fitdtw.npy )\n",
      "path_dtw_model...........: 02b_dtw_model.pkl ( ./Experimentos/2024-06-27_NivelProducto/02b_dtw_model.pkl )\n",
      "path_lag.................: 03_lag.parquet ( ./Experimentos/2024-06-27_NivelProducto/03_lag.parquet )\n",
      "path_train...............: 04_train.parquet ( ./Experimentos/2024-06-27_NivelProducto/04_train.parquet )\n",
      "path_test................: 04_test.parquet ( ./Experimentos/2024-06-27_NivelProducto/04_test.parquet )\n",
      "path_futuro..............: 04_futuro.parquet ( ./Experimentos/2024-06-27_NivelProducto/04_futuro.parquet )\n",
      "path_pred_test...........: 05_pred_test.parquet ( ./Experimentos/2024-06-27_NivelProducto/05_pred_test.parquet )\n",
      "path_pred_futuro.........: 05_pred_futuro.parquet ( ./Experimentos/2024-06-27_NivelProducto/05_pred_futuro.parquet )\n",
      "path_kaggle..............: kaggle_2024-06-27_NivelProducto.csv ( ./Experimentos/2024-06-27_NivelProducto/kaggle_2024-06-27_NivelProducto.csv )\n",
      "var_ejecutar_dtw.........: True\n",
      "var_clusters.............: [10]\n",
      "var_dibujar_dtw..........: False\n",
      "var_corte_prod_dtw.......: 20100\n",
      "var_leer_pickle_dtw......: True\n",
      "var_lags.................: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 18, 21, 24, 30, 36]\n",
      "var_cates_feat...........: ['cat1', 'cat2', 'brand', 'descripcion']\n",
      "var_exclusiones..........: []\n",
      "var_periodo_train_start..: 201701\n",
      "var_periodo_train_end....: 201910\n",
      "var_periodo_test.........: 201910\n",
      "var_periodo_futuro.......: 201912\n",
      "var_num_boost_round......: 2000\n",
      "var_lgbm_params..........: {'objective': 'regression', 'metric': ['l2', 'rmse'], 'boosting_type': 'gbdt', 'bagging_fraction': 0.9, 'bagging_freq': 1, 'num_leaves': 40, 'max_depth': -1, 'feature_fraction': 0.9, 'max_bin': 1023, 'learning_rate': 0.2, 'force_col_wise': True, 'num_threads': 8, 'verbose': 1, 'early_stopping_rounds': 10}\n",
      "var_dibujar_pesos........: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_stdout = sys.stdout \n",
    "\n",
    "with open(f'{FOLDER}\\exp_config_out.txt', 'w') as file:\n",
    "    sys.stdout = file\n",
    "\n",
    "    print(f\"{'Experimento':.^120}\\n{gen_config['nombre_exp']:-^120}\")\n",
    "    print(f\"{'CARPETA':.<25}: {gen_config['folder']}\")\n",
    "    for k, v in gen_config.items():\n",
    "        if k == 'folder' or k == 'nombre_exp':\n",
    "            continue\n",
    "        if k.startswith('path_'):\n",
    "            print(f\"{k:.<25}: {v} ( {FOLDER}{v} )\")\n",
    "        if k.startswith('var_'):\n",
    "            print(f\"{k:.<25}: {v}\")\n",
    "\n",
    "sys.stdout = original_stdout\n",
    "\n",
    "with open(f'{FOLDER}\\exp_config_out.txt', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "------------------------------------------01_LecturaDatos-------------------------------------------\n",
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "--------------------------------------------02_normaliza--------------------------------------------\n",
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "----------------------------------------------02b_DTW-----------------------------------------------\n",
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "--------------------------------------------03_features---------------------------------------------\n",
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "-----------------------------------------04_crear_train_set-----------------------------------------\n",
      "----------------------------------------------SALTEADO----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "a las 18:50:10\n",
      "----------------------------------------------COMIENZA----------------------------------------------\n",
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df_train...........: (2173865, 188)\n",
      "Shape df_test............: (68823, 188)\n",
      "Shape df_futuro..........: (53008, 188)\n",
      "Nulos en tn_futuro de Test: 51079\n",
      "Shape df_test dropna.....: (17744, 188)\n",
      "DISTRIBUCION DE DATOS EN CLUSTERS:\n",
      "          train  train_prop  test  test_prop  futuro  futuro_prop\n",
      "cluster                                                          \n",
      "0        179653    0.082642  2212   0.124662    4356     0.082176\n",
      "1        174193    0.080131   396   0.022317    5424     0.102324\n",
      "2        250628    0.115291  2002   0.112827    5358     0.101079\n",
      "3        317325    0.145973  3928   0.221371    7276     0.137262\n",
      "4        291646    0.134160  1159   0.065318    6279     0.118454\n",
      "5        185434    0.085302  1543   0.086959    5119     0.096570\n",
      "6        136073    0.062595  1818   0.102457    3082     0.058142\n",
      "7        148670    0.068390   586   0.033025    4580     0.086402\n",
      "8        186891    0.085972  2907   0.163830    4402     0.083044\n",
      "9        303352    0.139545  1193   0.067234    7132     0.134546\n",
      "Convertidas a categorical: ['yearquarter', 'cat1', 'cat2', 'cat3', 'brand', 'descripcion', 'cluster_dtw_10']\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 0\n",
      "Shape X_train............: (179653, 187)\n",
      "Shape X_test.............: (2212, 187)\n",
      "Shape X_futuro...........: (4356, 187)\n",
      "Shape y_train............: (179653,)\n",
      "Shape y_test.............: (2212,)\n",
      "Shape y_futuro...........: (4356,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 100301\n",
      "[LightGBM] [Info] Number of data points in the train set: 179653, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score -0.106002\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l2: 0.192202\ttraining's rmse: 0.438408\tvalid_1's l2: 0.0782565\tvalid_1's rmse: 0.279744\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 1\n",
      "Shape X_train............: (174193, 187)\n",
      "Shape X_test.............: (396, 187)\n",
      "Shape X_futuro...........: (5424, 187)\n",
      "Shape y_train............: (174193,)\n",
      "Shape y_test.............: (396,)\n",
      "Shape y_futuro...........: (5424,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 51655\n",
      "[LightGBM] [Info] Number of data points in the train set: 174193, number of used features: 143\n",
      "[LightGBM] [Info] Start training from score 0.184743\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1148]\ttraining's l2: 0.0246567\ttraining's rmse: 0.157025\tvalid_1's l2: 0.0628033\tvalid_1's rmse: 0.250606\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 2\n",
      "Shape X_train............: (250628, 187)\n",
      "Shape X_test.............: (2002, 187)\n",
      "Shape X_futuro...........: (5358, 187)\n",
      "Shape y_train............: (250628,)\n",
      "Shape y_test.............: (2002,)\n",
      "Shape y_futuro...........: (5358,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 98674\n",
      "[LightGBM] [Info] Number of data points in the train set: 250628, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score 0.049890\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\ttraining's l2: 0.260951\ttraining's rmse: 0.510834\tvalid_1's l2: 0.122328\tvalid_1's rmse: 0.349753\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 3\n",
      "Shape X_train............: (317325, 187)\n",
      "Shape X_test.............: (3928, 187)\n",
      "Shape X_futuro...........: (7276, 187)\n",
      "Shape y_train............: (317325,)\n",
      "Shape y_test.............: (3928,)\n",
      "Shape y_futuro...........: (7276,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 100433\n",
      "[LightGBM] [Info] Number of data points in the train set: 317325, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -0.013736\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l2: 0.353454\ttraining's rmse: 0.59452\tvalid_1's l2: 0.154697\tvalid_1's rmse: 0.393315\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 4\n",
      "Shape X_train............: (291646, 187)\n",
      "Shape X_test.............: (1159, 187)\n",
      "Shape X_futuro...........: (6279, 187)\n",
      "Shape y_train............: (291646,)\n",
      "Shape y_test.............: (1159,)\n",
      "Shape y_futuro...........: (6279,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 90604\n",
      "[LightGBM] [Info] Number of data points in the train set: 291646, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score 0.058565\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1031]\ttraining's l2: 0.480774\ttraining's rmse: 0.693379\tvalid_1's l2: 0.384363\tvalid_1's rmse: 0.61997\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 5\n",
      "Shape X_train............: (185434, 187)\n",
      "Shape X_test.............: (1543, 187)\n",
      "Shape X_futuro...........: (5119, 187)\n",
      "Shape y_train............: (185434,)\n",
      "Shape y_test.............: (1543,)\n",
      "Shape y_futuro...........: (5119,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 93291\n",
      "[LightGBM] [Info] Number of data points in the train set: 185434, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score -0.289357\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1998]\ttraining's l2: 0.095876\ttraining's rmse: 0.309639\tvalid_1's l2: 0.0567631\tvalid_1's rmse: 0.23825\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 6\n",
      "Shape X_train............: (136073, 187)\n",
      "Shape X_test.............: (1818, 187)\n",
      "Shape X_futuro...........: (3082, 187)\n",
      "Shape y_train............: (136073,)\n",
      "Shape y_test.............: (1818,)\n",
      "Shape y_futuro...........: (3082,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 100618\n",
      "[LightGBM] [Info] Number of data points in the train set: 136073, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score 0.054853\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l2: 0.137168\ttraining's rmse: 0.370361\tvalid_1's l2: 0.073457\tvalid_1's rmse: 0.271029\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 7\n",
      "Shape X_train............: (148670, 187)\n",
      "Shape X_test.............: (586, 187)\n",
      "Shape X_futuro...........: (4580, 187)\n",
      "Shape y_train............: (148670,)\n",
      "Shape y_test.............: (586,)\n",
      "Shape y_futuro...........: (4580,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 79220\n",
      "[LightGBM] [Info] Number of data points in the train set: 148670, number of used features: 166\n",
      "[LightGBM] [Info] Start training from score -0.268637\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1005]\ttraining's l2: 0.173286\ttraining's rmse: 0.416277\tvalid_1's l2: 0.182413\tvalid_1's rmse: 0.427098\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 8\n",
      "Shape X_train............: (186891, 187)\n",
      "Shape X_test.............: (2907, 187)\n",
      "Shape X_futuro...........: (4402, 187)\n",
      "Shape y_train............: (186891,)\n",
      "Shape y_test.............: (2907,)\n",
      "Shape y_futuro...........: (4402,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 100919\n",
      "[LightGBM] [Info] Number of data points in the train set: 186891, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score -0.018001\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l2: 0.221721\ttraining's rmse: 0.470872\tvalid_1's l2: 0.102715\tvalid_1's rmse: 0.320491\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 9\n",
      "Shape X_train............: (303352, 187)\n",
      "Shape X_test.............: (1193, 187)\n",
      "Shape X_futuro...........: (7132, 187)\n",
      "Shape y_train............: (303352,)\n",
      "Shape y_test.............: (1193,)\n",
      "Shape y_futuro...........: (7132,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 86804\n",
      "[LightGBM] [Info] Number of data points in the train set: 303352, number of used features: 174\n",
      "[LightGBM] [Info] Start training from score 0.046743\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l2: 0.287412\ttraining's rmse: 0.536108\tvalid_1's l2: 0.19287\tvalid_1's rmse: 0.43917\n",
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n",
      "----------------------------------------------FINALIZA----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "a las 18:56:52\n",
      "----------------------------------------------COMIENZA----------------------------------------------\n",
      "---------------------------------------06_evaluar_prediccion----------------------------------------\n",
      "Perdida en test: 0.05560616831907117\n",
      "Primeras filas de test:\n",
      "    product_id  tn_futuro_real  tn_prediccion_real     error\n",
      "0        20001      1286.02350         1200.982169 -6.612735\n",
      "1        20002      1002.49082         1008.570075  0.606415\n",
      "2        20003       680.22322          675.295500 -0.724427\n",
      "3        20004       506.69680          488.127555 -3.664765\n",
      "4        20005       491.74883          492.244448  0.100787\n",
      "31       20032       402.43544          395.993018 -1.600859\n",
      "Primeras filas de futuro:\n",
      "   product_id  tn_futuro_real  tn_prediccion_real\n",
      "0       20001             0.0         1287.029512\n",
      "1       20002             0.0          918.635726\n",
      "2       20003             0.0          787.346317\n",
      "3       20004             0.0          467.820225\n",
      "4       20005             0.0          505.672384\n",
      "5       20006             0.0          441.623362\n",
      "---------------------------------------06_evaluar_prediccion----------------------------------------\n",
      "----------------------------------------------FINALIZA----------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if ejecutar_scripts['01_LecturaDatos']:\n",
    "    print(f\"a las {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    %run 01_LecturaDatos.ipynb\n",
    "else:\n",
    "    print(f\"{'SALTEADO':-^100}\")\n",
    "    print(f\"{'01_LecturaDatos':-^100}\")\n",
    "    print(f\"{'SALTEADO':-^100}\\n\\n\\n\")\n",
    "\n",
    "if ejecutar_scripts['02_normaliza']:\n",
    "    print(f\"a las {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    %run 02_normaliza.ipynb\n",
    "else:\n",
    "    print(f\"{'SALTEADO':-^100}\")\n",
    "    print(f\"{'02_normaliza':-^100}\")\n",
    "    print(f\"{'SALTEADO':-^100}\\n\\n\\n\")\n",
    "\n",
    "if ejecutar_scripts['02b_DTW']:\n",
    "    print(f\"a las {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    %run 02b_DTW.ipynb\n",
    "else:\n",
    "    print(f\"{'SALTEADO':-^100}\")\n",
    "    print(f\"{'02b_DTW':-^100}\")\n",
    "    print(f\"{'SALTEADO':-^100}\\n\\n\\n\")\n",
    "\n",
    "if ejecutar_scripts['03_features']:\n",
    "    print(f\"a las {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    %run 03_features.ipynb\n",
    "else:\n",
    "    print(f\"{'SALTEADO':-^100}\")\n",
    "    print(f\"{'03_features':-^100}\")\n",
    "    print(f\"{'SALTEADO':-^100}\\n\\n\\n\")\n",
    "\n",
    "if ejecutar_scripts['04_crear_train_set']:\n",
    "    print(f\"a las {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    %run 04_crear_train_set.ipynb\n",
    "else:\n",
    "    print(f\"{'SALTEADO':-^100}\")\n",
    "    print(f\"{'04_crear_train_set':-^100}\")\n",
    "    print(f\"{'SALTEADO':-^100}\\n\\n\\n\")\n",
    "\n",
    "if ejecutar_scripts['05_lightgbm']:\n",
    "    print(f\"a las {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    %run 05_lightgbm.ipynb\n",
    "else:\n",
    "    print(f\"{'SALTEADO':-^100}\")\n",
    "    print(f\"{'05_lightgbm':-^100}\")\n",
    "    print(f\"{'SALTEADO':-^100}\\n\\n\\n\")\n",
    "\n",
    "if ejecutar_scripts['06_evaluar_prediccion']:\n",
    "    print(f\"a las {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    %run 06_evaluar_prediccion.ipynb\n",
    "else:\n",
    "    print(f\"{'SALTEADO':-^100}\")\n",
    "    print(f\"{'06_evaluar_prediccion':-^100}\")\n",
    "    print(f\"{'SALTEADO':-^100}\\n\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
