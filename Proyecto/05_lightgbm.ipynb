{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fase = '05_lightgbm (un intento)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_config.json', 'r') as file:\n",
    "    gen_config =json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------COMIENZA----------------------------------------------\n",
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "folder = gen_config['folder']\n",
    "\n",
    "path_pred_test = gen_config['path_pred_test']\n",
    "path_pred_futuro = gen_config['path_pred_futuro']\n",
    "path_prod_stats = gen_config['path_prod_stats']\n",
    "\n",
    "path_train = gen_config['path_train']\n",
    "path_test = gen_config['path_test']\n",
    "path_futuro = gen_config['path_futuro']\n",
    "\n",
    "lgbm_params = gen_config['var_lgbm_params']\n",
    "exclusiones = gen_config['var_exclusiones']\n",
    "dibujar_pesos = gen_config['var_dibujar_pesos']\n",
    "var_num_boost_round = gen_config['var_num_boost_round']\n",
    "\n",
    "print(f\"{'COMIENZA':-^100}\")\n",
    "print(f\"{fase:-^100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df_train...........: (2173865, 188)\n",
      "Shape df_test............: (68823, 188)\n",
      "Shape df_futuro..........: (53008, 188)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_parquet(f\"{folder}/{path_train}\")\n",
    "df_test = pd.read_parquet(f\"{folder}/{path_test}\")\n",
    "df_futuro = pd.read_parquet(f\"{folder}/{path_futuro}\")\n",
    "\n",
    "prod_stats = pd.read_parquet(f\"{folder}/{path_prod_stats}\")\n",
    "prod_stats = prod_stats[['product_id','customer_id', 'average_tn', 'std_dev_tn']]\n",
    "\n",
    "print(f\"{'Shape df_train':.<25}: {df_train.shape}\")\n",
    "print(f\"{'Shape df_test':.<25}: {df_test.shape}\")\n",
    "print(f\"{'Shape df_futuro':.<25}: {df_futuro.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos en tn_futuro de Test: 51079\n",
      "Shape df_test dropna.....: (17744, 188)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nulos en tn_futuro de Test: {df_test['tn_futuro'].isna().sum()}\")\n",
    "#df_test['tn_futuro'] = df_test['tn_futuro'].fillna(0)\n",
    "df_test.dropna(subset=['tn_futuro'], inplace=True)\n",
    "print(f\"{'Shape df_test dropna':.<25}: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRIBUCION DE DATOS EN CLUSTERS:\n",
      "          train  train_prop  test  test_prop  futuro  futuro_prop\n",
      "cluster                                                          \n",
      "0        179653    0.082642  2212   0.124662    4356     0.082176\n",
      "1        174193    0.080131   396   0.022317    5424     0.102324\n",
      "2        250628    0.115291  2002   0.112827    5358     0.101079\n",
      "3        317325    0.145973  3928   0.221371    7276     0.137262\n",
      "4        291646    0.134160  1159   0.065318    6279     0.118454\n",
      "5        185434    0.085302  1543   0.086959    5119     0.096570\n",
      "6        136073    0.062595  1818   0.102457    3082     0.058142\n",
      "7        148670    0.068390   586   0.033025    4580     0.086402\n",
      "8        186891    0.085972  2907   0.163830    4402     0.083044\n",
      "9        303352    0.139545  1193   0.067234    7132     0.134546\n"
     ]
    }
   ],
   "source": [
    "distribution_report = pd.DataFrame(range(0,10), columns=['cluster'])\n",
    "distribution_report['train'] = df_train[['cluster_dtw_10','periodo']].groupby('cluster_dtw_10').count()\n",
    "distribution_report['train_prop'] = distribution_report['train'] / distribution_report['train'].sum()\n",
    "distribution_report['test'] = df_test[['cluster_dtw_10','periodo']].groupby('cluster_dtw_10').count()\n",
    "distribution_report['test_prop'] = distribution_report['test'] / distribution_report['test'].sum()\n",
    "distribution_report['futuro'] = df_futuro[['cluster_dtw_10','periodo']].groupby('cluster_dtw_10').count()\n",
    "distribution_report['futuro_prop'] = distribution_report['futuro'] / distribution_report['futuro'].sum()\n",
    "distribution_report.set_index('cluster', inplace=True)\n",
    "\n",
    "print(f\"DISTRIBUCION DE DATOS EN CLUSTERS:\\n{distribution_report.head(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertidas a categorical: ['yearquarter', 'cat1', 'cat2', 'cat3', 'brand', 'descripcion', 'cluster_dtw_10']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df_train.select_dtypes(['category']).columns.tolist()\n",
    "for col in categorical_features:\n",
    "    df_train[col] = df_train[col].cat.codes\n",
    "    df_test[col] = df_test[col].cat.codes\n",
    "    df_futuro[col] = df_futuro[col].cat.codes\n",
    "print(f\"Convertidas a categorical: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_cluster_ttf(df_train, df_test, df_futuro, cluster_col, cluster):\n",
    "    X_train = df_train[df_train[cluster_col] == cluster].iloc[:,:-1]\n",
    "    X_test = df_test[df_test[cluster_col] == cluster].iloc[:,:-1]\n",
    "    X_futuro = df_futuro[df_futuro[cluster_col] == cluster].iloc[:,:-1]\n",
    "\n",
    "    y_train = df_train[df_train[cluster_col] == cluster].iloc[:,-1]\n",
    "    y_test = df_test[df_test[cluster_col] == cluster].iloc[:,-1]\n",
    "    y_futuro = df_futuro[df_futuro[cluster_col] == cluster].iloc[:,-1]\n",
    "\n",
    "    print(f\"{'Cluster Column':.<25}: {cluster_col}\")\n",
    "    print(f\"{'Cluster':.<25}: {cluster}\")\n",
    "    print(f\"{'Shape X_train':.<25}: {X_train.shape}\")\n",
    "    print(f\"{'Shape X_test':.<25}: {X_test.shape}\")\n",
    "    print(f\"{'Shape X_futuro':.<25}: {X_futuro.shape}\")\n",
    "\n",
    "    print(f\"{'Shape y_train':.<25}: {y_train.shape}\")\n",
    "    print(f\"{'Shape y_test':.<25}: {y_test.shape}\")\n",
    "    print(f\"{'Shape y_futuro':.<25}: {y_futuro.shape}\")\n",
    "    print(f\"\\n\")\n",
    "\n",
    "    return X_train, X_test, X_futuro, y_train, y_test, y_futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster(X_train, X_test, X_futuro, y_train, y_test, y_futuro):\n",
    "\n",
    "    train_data = lgb.Dataset(X_train.drop(columns=exclusiones), label=y_train)\n",
    "    test_data = lgb.Dataset(X_test.drop(columns=exclusiones), label=y_test)\n",
    "    #futuro_data = lgb.Dataset(X_futuro.drop(columns=exclusiones), label=y_futuro)\n",
    "\n",
    "    params = lgbm_params\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=var_num_boost_round,\n",
    "                    valid_sets=[train_data, test_data],\n",
    "                    )\n",
    "\n",
    "    y_pred = model.predict(X_test.drop(columns=exclusiones), num_iteration=model.best_iteration)\n",
    "    y_pred_futuro = model.predict(X_futuro.drop(columns=exclusiones), num_iteration=model.best_iteration)\n",
    "\n",
    "    return model, y_pred, y_pred_futuro\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 0\n",
      "Shape X_train............: (179653, 187)\n",
      "Shape X_test.............: (2212, 187)\n",
      "Shape X_futuro...........: (4356, 187)\n",
      "Shape y_train............: (179653,)\n",
      "Shape y_test.............: (2212,)\n",
      "Shape y_futuro...........: (4356,)\n",
      "[LightGBM] [Info] Total Bins 100301\n",
      "[LightGBM] [Info] Number of data points in the train set: 179653, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score -0.106002\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 0.679935\ttraining's rmse: 0.824582\tvalid_1's l2: 0.526368\tvalid_1's rmse: 0.725512\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 1\n",
      "Shape X_train............: (174193, 187)\n",
      "Shape X_test.............: (396, 187)\n",
      "Shape X_futuro...........: (5424, 187)\n",
      "Shape y_train............: (174193,)\n",
      "Shape y_test.............: (396,)\n",
      "Shape y_futuro...........: (5424,)\n",
      "[LightGBM] [Info] Total Bins 51655\n",
      "[LightGBM] [Info] Number of data points in the train set: 174193, number of used features: 143\n",
      "[LightGBM] [Info] Start training from score 0.184743\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 0.0968609\ttraining's rmse: 0.311225\tvalid_1's l2: 0.401211\tvalid_1's rmse: 0.633412\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 2\n",
      "Shape X_train............: (250628, 187)\n",
      "Shape X_test.............: (2002, 187)\n",
      "Shape X_futuro...........: (5358, 187)\n",
      "Shape y_train............: (250628,)\n",
      "Shape y_test.............: (2002,)\n",
      "Shape y_futuro...........: (5358,)\n",
      "[LightGBM] [Info] Total Bins 98674\n",
      "[LightGBM] [Info] Number of data points in the train set: 250628, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score 0.049890\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 0.803428\ttraining's rmse: 0.896342\tvalid_1's l2: 0.841613\tvalid_1's rmse: 0.917395\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 3\n",
      "Shape X_train............: (317325, 187)\n",
      "Shape X_test.............: (3928, 187)\n",
      "Shape X_futuro...........: (7276, 187)\n",
      "Shape y_train............: (317325,)\n",
      "Shape y_test.............: (3928,)\n",
      "Shape y_futuro...........: (7276,)\n",
      "[LightGBM] [Info] Total Bins 100433\n",
      "[LightGBM] [Info] Number of data points in the train set: 317325, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -0.013736\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 0.7929\ttraining's rmse: 0.890449\tvalid_1's l2: 0.483998\tvalid_1's rmse: 0.6957\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 4\n",
      "Shape X_train............: (291646, 187)\n",
      "Shape X_test.............: (1159, 187)\n",
      "Shape X_futuro...........: (6279, 187)\n",
      "Shape y_train............: (291646,)\n",
      "Shape y_test.............: (1159,)\n",
      "Shape y_futuro...........: (6279,)\n",
      "[LightGBM] [Info] Total Bins 90604\n",
      "[LightGBM] [Info] Number of data points in the train set: 291646, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score 0.058565\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 0.723344\ttraining's rmse: 0.850497\tvalid_1's l2: 0.80433\tvalid_1's rmse: 0.896845\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 5\n",
      "Shape X_train............: (185434, 187)\n",
      "Shape X_test.............: (1543, 187)\n",
      "Shape X_futuro...........: (5119, 187)\n",
      "Shape y_train............: (185434,)\n",
      "Shape y_test.............: (1543,)\n",
      "Shape y_futuro...........: (5119,)\n",
      "[LightGBM] [Info] Total Bins 93291\n",
      "[LightGBM] [Info] Number of data points in the train set: 185434, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score -0.289357\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 0.310481\ttraining's rmse: 0.557208\tvalid_1's l2: 0.265862\tvalid_1's rmse: 0.515618\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 6\n",
      "Shape X_train............: (136073, 187)\n",
      "Shape X_test.............: (1818, 187)\n",
      "Shape X_futuro...........: (3082, 187)\n",
      "Shape y_train............: (136073,)\n",
      "Shape y_test.............: (1818,)\n",
      "Shape y_futuro...........: (3082,)\n",
      "[LightGBM] [Info] Total Bins 100618\n",
      "[LightGBM] [Info] Number of data points in the train set: 136073, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score 0.054853\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 0.792964\ttraining's rmse: 0.890485\tvalid_1's l2: 0.948573\tvalid_1's rmse: 0.973947\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 7\n",
      "Shape X_train............: (148670, 187)\n",
      "Shape X_test.............: (586, 187)\n",
      "Shape X_futuro...........: (4580, 187)\n",
      "Shape y_train............: (148670,)\n",
      "Shape y_test.............: (586,)\n",
      "Shape y_futuro...........: (4580,)\n",
      "[LightGBM] [Info] Total Bins 79220\n",
      "[LightGBM] [Info] Number of data points in the train set: 148670, number of used features: 166\n",
      "[LightGBM] [Info] Start training from score -0.268637\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[993]\ttraining's l2: 0.383418\ttraining's rmse: 0.619208\tvalid_1's l2: 0.539106\tvalid_1's rmse: 0.734238\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 8\n",
      "Shape X_train............: (186891, 187)\n",
      "Shape X_test.............: (2907, 187)\n",
      "Shape X_futuro...........: (4402, 187)\n",
      "Shape y_train............: (186891,)\n",
      "Shape y_test.............: (2907,)\n",
      "Shape y_futuro...........: (4402,)\n",
      "[LightGBM] [Info] Total Bins 100919\n",
      "[LightGBM] [Info] Number of data points in the train set: 186891, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score -0.018001\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l2: 0.776615\ttraining's rmse: 0.881258\tvalid_1's l2: 0.578721\tvalid_1's rmse: 0.760737\n",
      "Cluster Column...........: cluster_dtw_10\n",
      "Cluster..................: 9\n",
      "Shape X_train............: (303352, 187)\n",
      "Shape X_test.............: (1193, 187)\n",
      "Shape X_futuro...........: (7132, 187)\n",
      "Shape y_train............: (303352,)\n",
      "Shape y_test.............: (1193,)\n",
      "Shape y_futuro...........: (7132,)\n",
      "[LightGBM] [Info] Total Bins 86804\n",
      "[LightGBM] [Info] Number of data points in the train set: 303352, number of used features: 174\n",
      "[LightGBM] [Info] Start training from score 0.046743\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\ttraining's l2: 0.655264\ttraining's rmse: 0.809484\tvalid_1's l2: 0.67087\tvalid_1's rmse: 0.819067\n"
     ]
    }
   ],
   "source": [
    "modelos = []\n",
    "pred_final = pd.DataFrame()\n",
    "pred_final_futuro = pd.DataFrame()\n",
    "\n",
    "for cluster in range(0,10):\n",
    "    X_train, X_test, X_futuro, y_train, y_test, y_futuro = separar_cluster_ttf(df_train, df_test, df_futuro, 'cluster_dtw_10', cluster)\n",
    "    model, y_pred, y_pred_futuro = train_cluster(X_train, X_test, X_futuro, y_train, y_test, y_futuro)\n",
    "\n",
    "    modelos.append(model)\n",
    "\n",
    "    pred = X_test[['periodo','product_id','customer_id','tn_norm']]\n",
    "    pred['cluster'] = cluster\n",
    "    pred['tn_futuro'] = y_test\n",
    "    pred['tn_prediccion'] = y_pred\n",
    "    pred_final = pd.concat([pred_final, pred], ignore_index=True, axis=0)\n",
    "\n",
    "    pred_futuro =X_futuro[['periodo','product_id','customer_id','tn_norm']]\n",
    "    pred_futuro['cluster'] = cluster\n",
    "    pred_futuro['tn_futuro'] = y_futuro\n",
    "    pred_futuro['tn_prediccion'] = y_pred_futuro\n",
    "    pred_final_futuro = pd.concat([pred_final_futuro, pred_futuro], ignore_index=True, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pred_final.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "final['tn_futuro_real'] = (final['tn_norm'] + final['tn_futuro']) * final['std_dev_tn'] + final['average_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "final['tn_prediccion_real'] = (final['tn_norm'] + final['tn_prediccion']) * final['std_dev_tn'] + final['average_tn']\n",
    "final.to_parquet(f'{folder}/{path_pred_test}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_futuro = pred_final_futuro.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "final_futuro['tn_futuro_real'] = (final_futuro['tn_norm'] + final_futuro['tn_futuro']) * final_futuro['std_dev_tn'] + final_futuro['average_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "final_futuro['tn_prediccion_real'] = (final_futuro['tn_norm'] + final_futuro['tn_prediccion']) * final_futuro['std_dev_tn'] + final_futuro['average_tn']\n",
    "final_futuro.to_parquet(f'{folder}/{path_pred_futuro}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estado_control = f\"05_lightgbm Terminado - {nombrefile} - {datetime.now()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb.plot_importance(model, max_num_features=20, figsize=(10,10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_df = (\n",
    "#     pd.DataFrame({\n",
    "#         'feature_name': model.feature_name(),\n",
    "#         'importance_gain': model.feature_importance(importance_type='gain'),\n",
    "#         'importance_split': model.feature_importance(importance_type='split'),\n",
    "#     })\n",
    "#     .sort_values('importance_gain', ascending=False)\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "# importance_df.sort_values('importance_split', ascending=False, inplace=True)\n",
    "# feat_dibujar = importance_df[0:20]['feature_name'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dibujar_pesos==True:\n",
    "    fig, axs = plt.subplots(5, 4, figsize=(20, 25))\n",
    "    d = -1\n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            d+=1\n",
    "            lgb.plot_split_value_histogram(model,\n",
    "                            feature=feat_dibujar[d],\n",
    "                            bins=\"auto\",\n",
    "                            ax=axs[j, i]\n",
    "                            ,title=f\"Feat: {feat_dibujar[d]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n",
      "----------------------------------------------FINALIZA----------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{fase:-^100}\")\n",
    "print(f\"{'FINALIZA':-^100}\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
