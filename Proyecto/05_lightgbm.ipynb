{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fase = '05_lightgbm (un intento)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_config.json', 'r') as file:\n",
    "    gen_config =json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------COMIENZA----------------------------------------------\n",
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "folder = gen_config['folder']\n",
    "\n",
    "#entradas\n",
    "path_train = gen_config['path_train']\n",
    "path_test = gen_config['path_test']\n",
    "path_futuro = gen_config['path_futuro']\n",
    "path_prod_stats = gen_config['path_prod_stats']\n",
    "path_transform_stats = gen_config['path_transform_stats']\n",
    "#salidas\n",
    "path_pred_test = gen_config['path_pred_test']\n",
    "path_pred_futuro = gen_config['path_pred_futuro']\n",
    "#variables\n",
    "lgbm_params = gen_config['var_lgbm_params']\n",
    "exclusiones = gen_config['var_exclusiones']\n",
    "dibujar_pesos = gen_config['var_dibujar_pesos']\n",
    "var_num_boost_round = gen_config['var_num_boost_round']\n",
    "clusters = gen_config['var_clusters']\n",
    "\n",
    "print(f\"{'COMIENZA':-^100}\")\n",
    "print(f\"{fase:-^100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df_train...........: (4767503, 171)\n",
      "Shape df_test............: (178684, 171)\n",
      "Shape df_futuro..........: (178684, 171)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_parquet(f\"{folder}/{path_train}\")\n",
    "df_test = pd.read_parquet(f\"{folder}/{path_test}\")\n",
    "df_futuro = pd.read_parquet(f\"{folder}/{path_futuro}\")\n",
    "\n",
    "prod_stats = pd.read_parquet(f\"{folder}/{path_prod_stats}\")\n",
    "prod_stats = prod_stats[['product_id','customer_id', 'average_tn', 'std_dev_tn', 'total_tn', 'iqr_tn', 'median_tn']]\n",
    "transform_stats = pd.read_parquet(f\"{folder}/{path_transform_stats}\")\n",
    "\n",
    "print(f\"{'Shape df_train':.<25}: {df_train.shape}\")\n",
    "print(f\"{'Shape df_test':.<25}: {df_test.shape}\")\n",
    "print(f\"{'Shape df_futuro':.<25}: {df_futuro.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos en tn_futuro de Test: 0\n",
      "Shape df_test dropna.....: (178684, 171)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nulos en tn_futuro de Test: {df_test['tn_futuro'].isna().sum()}\")\n",
    "#df_test['tn_futuro'] = df_test['tn_futuro'].fillna(0)\n",
    "df_test.dropna(subset=['tn_futuro'], inplace=True)\n",
    "print(f\"{'Shape df_test dropna':.<25}: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.9,\n",
      " 'bagging_freq': 1,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'early_stopping_rounds': 10,\n",
      " 'feature_fraction': 0.9,\n",
      " 'force_col_wise': True,\n",
      " 'learning_rate': 0.01,\n",
      " 'max_bin': 1023,\n",
      " 'max_depth': -1,\n",
      " 'metric': ['l2', 'rmse'],\n",
      " 'num_leaves': 40,\n",
      " 'num_threads': 8,\n",
      " 'objective': 'regression',\n",
      " 'verbose': 1,\n",
      " 'weight_column': 'avg_weight'}\n"
     ]
    }
   ],
   "source": [
    "pprint(lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRIBUCION DE DATOS EN CLUSTERS:\n",
      "           train  train_prop    test  test_prop  futuro  futuro_prop\n",
      "cluster                                                             \n",
      "0         396428    0.083152   13031   0.072928   13031     0.072928\n",
      "1          13209    0.002771     407   0.002278     407     0.002278\n",
      "2         373202    0.078280   11702   0.065490   11702     0.065490\n",
      "3         248142    0.052049    7583   0.042438    7583     0.042438\n",
      "4         152397    0.031966    4743   0.026544    4743     0.026544\n",
      "5          87936    0.018445    4699   0.026298    4699     0.026298\n",
      "6         148173    0.031080    4860   0.027199    4860     0.027199\n",
      "7          46238    0.009699    2298   0.012861    2298     0.012861\n",
      "8           5997    0.001258     192   0.001075     192     0.001075\n",
      "9           1836    0.000385      97   0.000543      97     0.000543\n",
      "10       2814318    0.590313  114275   0.639537  114275     0.639537\n",
      "11           290    0.000061      10   0.000056      10     0.000056\n",
      "12         32259    0.006766    1232   0.006895    1232     0.006895\n",
      "13        266192    0.055835    8071   0.045169    8071     0.045169\n",
      "14        180886    0.037941    5484   0.030691    5484     0.030691\n"
     ]
    }
   ],
   "source": [
    "distribution_report = pd.DataFrame(range(0,clusters[0]), columns=['cluster'])\n",
    "distribution_report['train'] = df_train[[f'cluster_dtw_{clusters[0]}','periodo']].groupby(f'cluster_dtw_{clusters[0]}').count()\n",
    "distribution_report['train_prop'] = distribution_report['train'] / distribution_report['train'].sum()\n",
    "distribution_report['test'] = df_test[[f'cluster_dtw_{clusters[0]}','periodo']].groupby(f'cluster_dtw_{clusters[0]}').count()\n",
    "distribution_report['test_prop'] = distribution_report['test'] / distribution_report['test'].sum()\n",
    "distribution_report['futuro'] = df_futuro[[f'cluster_dtw_{clusters[0]}','periodo']].groupby(f'cluster_dtw_{clusters[0]}').count()\n",
    "distribution_report['futuro_prop'] = distribution_report['futuro'] / distribution_report['futuro'].sum()\n",
    "distribution_report.set_index('cluster', inplace=True)\n",
    "\n",
    "print(f\"DISTRIBUCION DE DATOS EN CLUSTERS:\\n{distribution_report.head(clusters[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_lgbm = df_train[f'cluster_dtw_{clusters[0]}'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertidas a categorical: ['yearquarter', 'edad', 'cat1', 'cat2', 'cat3', 'brand', 'descripcion', 'presentacion']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df_train.select_dtypes(['category']).columns.tolist()\n",
    "for col in categorical_features:\n",
    "    df_train[col] = df_train[col].cat.codes\n",
    "    df_test[col] = df_test[col].cat.codes\n",
    "    df_futuro[col] = df_futuro[col].cat.codes\n",
    "print(f\"Convertidas a categorical: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertidas a Boolean: ['primer_periodo_overall', 'ultimo_periodo_overall', 'max_2', 'max_3', 'max_4', 'max_5', 'max_6', 'max_7', 'max_8', 'max_9', 'max_10', 'max_11', 'max_12', 'max_13', 'max_15', 'max_18', 'crece_2', 'crece_3', 'crece_4', 'crece_5', 'crece_6', 'crece_7', 'crece_8', 'crece_9', 'crece_10', 'crece_11', 'crece_12', 'decrece_2', 'decrece_3', 'decrece_4', 'decrece_5', 'decrece_6', 'decrece_7', 'decrece_8', 'decrece_9', 'decrece_10', 'decrece_11', 'decrece_12']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df_train.select_dtypes(['object']).columns.tolist()\n",
    "for col in categorical_features:\n",
    "    df_train[col] = df_train[col].astype('bool')\n",
    "    df_test[col] = df_test[col].astype('bool')\n",
    "    df_futuro[col] = df_futuro[col].astype('bool')\n",
    "print(f\"Convertidas a Boolean: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_cluster_ttf(df_train, df_test, df_futuro, cluster_col, cluster):\n",
    "    X_train = df_train[df_train[cluster_col] == cluster].iloc[:,:-1]\n",
    "    X_test = df_test[df_test[cluster_col] == cluster].iloc[:,:-1]\n",
    "    X_futuro = df_futuro[df_futuro[cluster_col] == cluster].iloc[:,:-1]\n",
    "\n",
    "    y_train = df_train[df_train[cluster_col] == cluster].iloc[:,-1]\n",
    "    y_test = df_test[df_test[cluster_col] == cluster].iloc[:,-1]\n",
    "    y_futuro = df_futuro[df_futuro[cluster_col] == cluster].iloc[:,-1]\n",
    "\n",
    "    print(f\"{'Cluster Column':.<25}: {cluster_col}\")\n",
    "    print(f\"{'Cluster':.<25}: {cluster}\")\n",
    "    print(f\"{'Shape X_train':.<25}: {X_train.shape}\")\n",
    "    print(f\"{'Shape X_test':.<25}: {X_test.shape}\")\n",
    "    print(f\"{'Shape X_futuro':.<25}: {X_futuro.shape}\")\n",
    "\n",
    "    print(f\"{'Shape y_train':.<25}: {y_train.shape}\")\n",
    "    print(f\"{'Shape y_test':.<25}: {y_test.shape}\")\n",
    "    print(f\"{'Shape y_futuro':.<25}: {y_futuro.shape}\")\n",
    "    print(f\"\\n\")\n",
    "\n",
    "    return X_train, X_test, X_futuro, y_train, y_test, y_futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster(X_train, X_test, X_futuro, y_train, y_test, y_futuro):\n",
    "\n",
    "    train_data = lgb.Dataset(X_train.drop(columns=exclusiones), label=y_train)\n",
    "    test_data = lgb.Dataset(X_test.drop(columns=exclusiones), label=y_test)\n",
    "    #futuro_data = lgb.Dataset(X_futuro.drop(columns=exclusiones), label=y_futuro)\n",
    "\n",
    "    params = lgbm_params\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=var_num_boost_round,\n",
    "                    valid_sets=[test_data, train_data],\n",
    "                    )\n",
    "\n",
    "    y_pred = model.predict(X_test.drop(columns=exclusiones), num_iteration=model.best_iteration)\n",
    "    y_pred_futuro = model.predict(X_futuro.drop(columns=exclusiones), num_iteration=model.best_iteration)\n",
    "\n",
    "    return model, y_pred, y_pred_futuro\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 6\n",
      "Shape X_train............: (148173, 170)\n",
      "Shape X_test.............: (4860, 170)\n",
      "Shape X_futuro...........: (4860, 170)\n",
      "Shape y_train............: (148173,)\n",
      "Shape y_test.............: (4860,)\n",
      "Shape y_futuro...........: (4860,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87632\n",
      "[LightGBM] [Info] Number of data points in the train set: 148173, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score 0.072894\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttraining's l2: 9.69007\ttraining's rmse: 3.11289\tvalid_0's l2: 11.4173\tvalid_0's rmse: 3.37894\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 0\n",
      "Shape X_train............: (396428, 170)\n",
      "Shape X_test.............: (13031, 170)\n",
      "Shape X_futuro...........: (13031, 170)\n",
      "Shape y_train............: (396428,)\n",
      "Shape y_test.............: (13031,)\n",
      "Shape y_futuro...........: (13031,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87865\n",
      "[LightGBM] [Info] Number of data points in the train set: 396428, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score -0.000156\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[346]\ttraining's l2: 0.962387\ttraining's rmse: 0.981013\tvalid_0's l2: 0.410447\tvalid_0's rmse: 0.640662\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 3\n",
      "Shape X_train............: (248142, 170)\n",
      "Shape X_test.............: (7583, 170)\n",
      "Shape X_futuro...........: (7583, 170)\n",
      "Shape y_train............: (248142,)\n",
      "Shape y_test.............: (7583,)\n",
      "Shape y_futuro...........: (7583,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87319\n",
      "[LightGBM] [Info] Number of data points in the train set: 248142, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score -0.051154\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's l2: 2.16269\ttraining's rmse: 1.47061\tvalid_0's l2: 0.518787\tvalid_0's rmse: 0.720269\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 5\n",
      "Shape X_train............: (87936, 170)\n",
      "Shape X_test.............: (4699, 170)\n",
      "Shape X_futuro...........: (4699, 170)\n",
      "Shape y_train............: (87936,)\n",
      "Shape y_test.............: (4699,)\n",
      "Shape y_futuro...........: (4699,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87805\n",
      "[LightGBM] [Info] Number of data points in the train set: 87936, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score -0.046737\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\ttraining's l2: 1.06649\ttraining's rmse: 1.03271\tvalid_0's l2: 1.08074\tvalid_0's rmse: 1.03958\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 13\n",
      "Shape X_train............: (266192, 170)\n",
      "Shape X_test.............: (8071, 170)\n",
      "Shape X_futuro...........: (8071, 170)\n",
      "Shape y_train............: (266192,)\n",
      "Shape y_test.............: (8071,)\n",
      "Shape y_futuro...........: (8071,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87192\n",
      "[LightGBM] [Info] Number of data points in the train set: 266192, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score 0.023921\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\ttraining's l2: 1.0991\ttraining's rmse: 1.04838\tvalid_0's l2: 1.65417\tvalid_0's rmse: 1.28615\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 14\n",
      "Shape X_train............: (180886, 170)\n",
      "Shape X_test.............: (5484, 170)\n",
      "Shape X_futuro...........: (5484, 170)\n",
      "Shape y_train............: (180886,)\n",
      "Shape y_test.............: (5484,)\n",
      "Shape y_futuro...........: (5484,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87160\n",
      "[LightGBM] [Info] Number of data points in the train set: 180886, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score 0.019188\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's l2: 0.616027\ttraining's rmse: 0.784874\tvalid_0's l2: 0.730143\tvalid_0's rmse: 0.854484\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 2\n",
      "Shape X_train............: (373202, 170)\n",
      "Shape X_test.............: (11702, 170)\n",
      "Shape X_futuro...........: (11702, 170)\n",
      "Shape y_train............: (373202,)\n",
      "Shape y_test.............: (11702,)\n",
      "Shape y_futuro...........: (11702,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87689\n",
      "[LightGBM] [Info] Number of data points in the train set: 373202, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score -0.016822\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[340]\ttraining's l2: 1.41601\ttraining's rmse: 1.18996\tvalid_0's l2: 0.901041\tvalid_0's rmse: 0.949232\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 12\n",
      "Shape X_train............: (32259, 170)\n",
      "Shape X_test.............: (1232, 170)\n",
      "Shape X_futuro...........: (1232, 170)\n",
      "Shape y_train............: (32259,)\n",
      "Shape y_test.............: (1232,)\n",
      "Shape y_futuro...........: (1232,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87616\n",
      "[LightGBM] [Info] Number of data points in the train set: 32259, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score -0.003261\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[271]\ttraining's l2: 0.506139\ttraining's rmse: 0.711434\tvalid_0's l2: 0.431355\tvalid_0's rmse: 0.656776\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 8\n",
      "Shape X_train............: (5997, 170)\n",
      "Shape X_test.............: (192, 170)\n",
      "Shape X_futuro...........: (192, 170)\n",
      "Shape y_train............: (5997,)\n",
      "Shape y_test.............: (192,)\n",
      "Shape y_futuro...........: (192,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 37307\n",
      "[LightGBM] [Info] Number of data points in the train set: 5997, number of used features: 150\n",
      "[LightGBM] [Info] Start training from score -3.121200\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\ttraining's l2: 465924\ttraining's rmse: 682.586\tvalid_0's l2: 474780\tvalid_0's rmse: 689.043\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 4\n",
      "Shape X_train............: (152397, 170)\n",
      "Shape X_test.............: (4743, 170)\n",
      "Shape X_futuro...........: (4743, 170)\n",
      "Shape y_train............: (152397,)\n",
      "Shape y_test.............: (4743,)\n",
      "Shape y_futuro...........: (4743,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87582\n",
      "[LightGBM] [Info] Number of data points in the train set: 152397, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score 0.014786\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\ttraining's l2: 36.1541\ttraining's rmse: 6.01283\tvalid_0's l2: 35.9031\tvalid_0's rmse: 5.99192\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 7\n",
      "Shape X_train............: (46238, 170)\n",
      "Shape X_test.............: (2298, 170)\n",
      "Shape X_futuro...........: (2298, 170)\n",
      "Shape y_train............: (46238,)\n",
      "Shape y_test.............: (2298,)\n",
      "Shape y_futuro...........: (2298,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 87513\n",
      "[LightGBM] [Info] Number of data points in the train set: 46238, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score 0.016488\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\ttraining's l2: 0.663367\ttraining's rmse: 0.814473\tvalid_0's l2: 0.85101\tvalid_0's rmse: 0.922502\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 10\n",
      "Shape X_train............: (2814318, 170)\n",
      "Shape X_test.............: (114275, 170)\n",
      "Shape X_futuro...........: (114275, 170)\n",
      "Shape y_train............: (2814318,)\n",
      "Shape y_test.............: (114275,)\n",
      "Shape y_futuro...........: (114275,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 92479\n",
      "[LightGBM] [Info] Number of data points in the train set: 2814318, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score -0.016567\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's l2: 5846.19\ttraining's rmse: 76.4604\tvalid_0's l2: 6696.36\tvalid_0's rmse: 81.8313\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 1\n",
      "Shape X_train............: (13209, 170)\n",
      "Shape X_test.............: (407, 170)\n",
      "Shape X_futuro...........: (407, 170)\n",
      "Shape y_train............: (13209,)\n",
      "Shape y_test.............: (407,)\n",
      "Shape y_futuro...........: (407,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 69800\n",
      "[LightGBM] [Info] Number of data points in the train set: 13209, number of used features: 150\n",
      "[LightGBM] [Info] Start training from score 1.014449\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[335]\ttraining's l2: 21947.9\ttraining's rmse: 148.148\tvalid_0's l2: 56042.9\tvalid_0's rmse: 236.734\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 11\n",
      "Shape X_train............: (290, 170)\n",
      "Shape X_test.............: (10, 170)\n",
      "Shape X_futuro...........: (10, 170)\n",
      "Shape y_train............: (290,)\n",
      "Shape y_test.............: (10,)\n",
      "Shape y_futuro...........: (10,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 2722\n",
      "[LightGBM] [Info] Number of data points in the train set: 290, number of used features: 149\n",
      "[LightGBM] [Info] Start training from score -26.381609\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's l2: 8.0031e+08\ttraining's rmse: 28289.8\tvalid_0's l2: 5.59573e+09\tvalid_0's rmse: 74804.6\n",
      "Cluster Column...........: cluster_dtw_15\n",
      "Cluster..................: 9\n",
      "Shape X_train............: (1836, 170)\n",
      "Shape X_test.............: (97, 170)\n",
      "Shape X_futuro...........: (97, 170)\n",
      "Shape y_train............: (1836,)\n",
      "Shape y_test.............: (97,)\n",
      "Shape y_futuro...........: (97,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 10000\n",
      "[LightGBM] [Info] Number of data points in the train set: 1836, number of used features: 150\n",
      "[LightGBM] [Info] Start training from score 107.182403\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's l2: 3.51513e+07\ttraining's rmse: 5928.86\tvalid_0's l2: 1.34273e+07\tvalid_0's rmse: 3664.33\n"
     ]
    }
   ],
   "source": [
    "modelos = []\n",
    "pred_final = pd.DataFrame()\n",
    "pred_final_futuro = pd.DataFrame()\n",
    "\n",
    "for cluster in clusters_lgbm:\n",
    "    X_train, X_test, X_futuro, y_train, y_test, y_futuro = separar_cluster_ttf(df_train, df_test, df_futuro, f'cluster_dtw_{clusters[0]}', cluster)\n",
    "    model, y_pred, y_pred_futuro = train_cluster(X_train, X_test, X_futuro, y_train, y_test, y_futuro)\n",
    "\n",
    "    modelos.append(model)\n",
    "\n",
    "    pred = X_test[['periodo','product_id','customer_id','tn_norm']]\n",
    "    pred['cluster'] = cluster\n",
    "    pred['tn_futuro'] = y_test\n",
    "    pred['tn_prediccion'] = y_pred\n",
    "    pred_final = pd.concat([pred_final, pred], ignore_index=True, axis=0)\n",
    "\n",
    "    pred_futuro =X_futuro[['periodo','product_id','customer_id','tn_norm']]\n",
    "    pred_futuro['cluster'] = cluster\n",
    "    pred_futuro['tn_futuro'] = y_futuro\n",
    "    pred_futuro['tn_prediccion'] = y_pred_futuro\n",
    "    pred_final_futuro = pd.concat([pred_final_futuro, pred_futuro], ignore_index=True, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_inverse_transform(x_trans, lambda_, mean_, var_):\n",
    "    try:\n",
    "        x = x_trans.to_numpy().reshape(-1, 1)\n",
    "    except:\n",
    "        x = np.array(x_trans)\n",
    "\n",
    "    x = x * var_ ** 0.5 + mean_\n",
    "\n",
    "    x_inv = np.zeros_like(x)\n",
    "    pos = x >= 0\n",
    "\n",
    "    # when x >= 0\n",
    "    if abs(lambda_) < np.spacing(1.0):\n",
    "        x_inv[pos] = np.exp(x[pos]) - 1\n",
    "    else:  # lambda_ != 0\n",
    "        x_inv[pos] = np.power(x[pos] * lambda_ + 1, 1 / lambda_) - 1\n",
    "\n",
    "    # when x < 0\n",
    "    if abs(lambda_ - 2) > np.spacing(1.0):\n",
    "        x_inv[~pos] = 1 - np.power(-(2 - lambda_) * x[~pos] + 1, 1 / (2 - lambda_))\n",
    "    else:  # lambda_ == 2\n",
    "        x_inv[~pos] = 1 - np.exp(-x[~pos])\n",
    "\n",
    "    x_orig = x_inv.flatten()\n",
    "\n",
    "    return x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pred_final.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "#final = pred_final.merge(transform_stats, how='left', on=['product_id','customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #power transform\n",
    "# final['tn_futuro_real'] = final.apply(lambda row: power_inverse_transform((row['tn_norm'] + row['tn_futuro']), row['pwr_lambda'], row['pwr_mean'], row['pwr_var']), axis=1)\n",
    "# final['tn_futuro_real'] = [tn_inv[0] for tn_inv in final['tn_futuro_real']]\n",
    "# final['tn_prediccion_real'] = final.apply(lambda row: power_inverse_transform((row['tn_norm'] + row['tn_prediccion']), row['pwr_lambda'], row['pwr_mean'], row['pwr_var']), axis=1)\n",
    "# final['tn_prediccion_real'] = [tn_inv[0] for tn_inv in final['tn_prediccion_real']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robusta\n",
    "final['tn_futuro_real'] = (final['tn_norm'] + final['tn_futuro']) * final['iqr_tn'] + final['median_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "final['tn_prediccion_real'] = (final['tn_norm'] + final['tn_prediccion']) * final['iqr_tn'] + final['median_tn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_futuro = pred_final.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "#final_futuro = pred_final_futuro.merge(transform_stats, how='left', on=['product_id','customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #power transform\n",
    "# final_futuro['tn_futuro_real'] = final_futuro.apply(lambda row: power_inverse_transform((row['tn_norm'] + row['tn_futuro']), row['pwr_lambda'], row['pwr_mean'], row['pwr_var']), axis=1)\n",
    "# final_futuro['tn_futuro_real'] = [tn_inv[0] for tn_inv in final_futuro['tn_futuro_real']]\n",
    "# final_futuro['tn_prediccion_real'] = final_futuro.apply(lambda row: power_inverse_transform((row['tn_norm'] + row['tn_prediccion']), row['pwr_lambda'], row['pwr_mean'], row['pwr_var']), axis=1)\n",
    "# final_futuro['tn_prediccion_real'] = [tn_inv[0] for tn_inv in final_futuro['tn_prediccion_real']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robusta\n",
    "final_futuro['tn_futuro_real'] = (final_futuro['tn_norm'] + final_futuro['tn_futuro']) * final_futuro['iqr_tn'] + final_futuro['median_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "final_futuro['tn_prediccion_real'] = (final_futuro['tn_norm'] + final_futuro['tn_prediccion']) * final_futuro['iqr_tn'] + final_futuro['median_tn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = pred_final.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "# final['tn_futuro_real'] = (final['tn_norm'] + final['tn_futuro']) * final['std_dev_tn'] + final['average_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "# final['tn_prediccion_real'] = (final['tn_norm'] + final['tn_prediccion']) * final['std_dev_tn'] + final['average_tn']\n",
    "final.to_parquet(f'{folder}/{path_pred_test}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_futuro = pred_final_futuro.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "# final_futuro['tn_futuro_real'] = (final_futuro['tn_norm'] + final_futuro['tn_futuro']) * final_futuro['std_dev_tn'] + final_futuro['average_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "# final_futuro['tn_prediccion_real'] = (final_futuro['tn_norm'] + final_futuro['tn_prediccion']) * final_futuro['std_dev_tn'] + final_futuro['average_tn']\n",
    "final_futuro.to_parquet(f'{folder}/{path_pred_futuro}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estado_control = f\"05_lightgbm Terminado - {nombrefile} - {datetime.now()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb.plot_importance(model, max_num_features=20, figsize=(10,10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_df = (\n",
    "#     pd.DataFrame({\n",
    "#         'feature_name': model.feature_name(),\n",
    "#         'importance_gain': model.feature_importance(importance_type='gain'),\n",
    "#         'importance_split': model.feature_importance(importance_type='split'),\n",
    "#     })\n",
    "#     .sort_values('importance_gain', ascending=False)\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "# importance_df.sort_values('importance_split', ascending=False, inplace=True)\n",
    "# feat_dibujar = importance_df[0:20]['feature_name'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dibujar_pesos==True:\n",
    "    fig, axs = plt.subplots(5, 4, figsize=(20, 25))\n",
    "    d = -1\n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            d+=1\n",
    "            lgb.plot_split_value_histogram(model,\n",
    "                            feature=feat_dibujar[d],\n",
    "                            bins=\"auto\",\n",
    "                            ax=axs[j, i]\n",
    "                            ,title=f\"Feat: {feat_dibujar[d]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n",
      "----------------------------------------------FINALIZA----------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{fase:-^100}\")\n",
    "print(f\"{'FINALIZA':-^100}\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
