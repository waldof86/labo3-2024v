{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fase = '05_lightgbm (un intento)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_config.json', 'r') as file:\n",
    "    gen_config =json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------COMIENZA----------------------------------------------\n",
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "folder = gen_config['folder']\n",
    "\n",
    "path_pred_test = gen_config['path_pred_test']\n",
    "path_pred_futuro = gen_config['path_pred_futuro']\n",
    "path_prod_stats = gen_config['path_prod_stats']\n",
    "\n",
    "path_train = gen_config['path_train']\n",
    "path_test = gen_config['path_test']\n",
    "path_futuro = gen_config['path_futuro']\n",
    "\n",
    "lgbm_params = gen_config['var_lgbm_params']\n",
    "exclusiones = gen_config['var_exclusiones']\n",
    "dibujar_pesos = gen_config['var_dibujar_pesos']\n",
    "var_num_boost_round = gen_config['var_num_boost_round']\n",
    "clusters = gen_config['var_clusters']\n",
    "\n",
    "print(f\"{'COMIENZA':-^100}\")\n",
    "print(f\"{fase:-^100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df_train...........: (2105042, 190)\n",
      "Shape df_test............: (68823, 190)\n",
      "Shape df_futuro..........: (53008, 190)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_parquet(f\"{folder}/{path_train}\")\n",
    "df_test = pd.read_parquet(f\"{folder}/{path_test}\")\n",
    "df_futuro = pd.read_parquet(f\"{folder}/{path_futuro}\")\n",
    "\n",
    "prod_stats = pd.read_parquet(f\"{folder}/{path_prod_stats}\")\n",
    "prod_stats = prod_stats[['product_id','customer_id', 'average_tn', 'std_dev_tn', 'total_tn']]\n",
    "\n",
    "print(f\"{'Shape df_train':.<25}: {df_train.shape}\")\n",
    "print(f\"{'Shape df_test':.<25}: {df_test.shape}\")\n",
    "print(f\"{'Shape df_futuro':.<25}: {df_futuro.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos en tn_futuro de Test: 51082\n",
      "Shape df_test dropna.....: (17741, 190)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nulos en tn_futuro de Test: {df_test['tn_futuro'].isna().sum()}\")\n",
    "#df_test['tn_futuro'] = df_test['tn_futuro'].fillna(0)\n",
    "df_test.dropna(subset=['tn_futuro'], inplace=True)\n",
    "print(f\"{'Shape df_test dropna':.<25}: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.9,\n",
      " 'bagging_freq': 1,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'early_stopping_rounds': 10,\n",
      " 'feature_fraction': 0.9,\n",
      " 'force_col_wise': True,\n",
      " 'learning_rate': 0.01,\n",
      " 'max_bin': 1023,\n",
      " 'max_depth': -1,\n",
      " 'metric': ['l2', 'rmse'],\n",
      " 'num_leaves': 40,\n",
      " 'num_threads': 8,\n",
      " 'objective': 'regression',\n",
      " 'verbose': 1,\n",
      " 'weight_column': 'avg_weight'}\n"
     ]
    }
   ],
   "source": [
    "pprint(lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRIBUCION DE DATOS EN CLUSTERS:\n",
      "          train  train_prop  test  test_prop  futuro  futuro_prop\n",
      "cluster                                                          \n",
      "0         35809    0.020373   212   0.011950    1107     0.022224\n",
      "1         51551    0.029329   951   0.053605    1360     0.027304\n",
      "2         66039    0.037572   494   0.027845    1580     0.031721\n",
      "3         60514    0.034428   428   0.024125    3328     0.066814\n",
      "4         66069    0.037589   652   0.036751    1488     0.029874\n",
      "5         54427    0.030965   654   0.036864    1354     0.027183\n",
      "6         58743    0.033421   381   0.021476    1425     0.028609\n",
      "7         75021    0.042682   303   0.017079    1738     0.034893\n",
      "8         48484    0.027584   979   0.055183    1318     0.026461\n",
      "9         50936    0.028979   385   0.021701    2242     0.045011\n",
      "10        49795    0.028330   505   0.028465    1094     0.021963\n",
      "11        58565    0.033319   298   0.016797    1331     0.026722\n",
      "12       107370    0.061086   793   0.044699    4725     0.094860\n",
      "13        81302    0.046255   571   0.032185    2332     0.046818\n",
      "14        59480    0.033840   723   0.040753    1461     0.029331\n",
      "15        82259    0.046800   553   0.031171    2050     0.041156\n",
      "16        82286    0.046815   378   0.021307    2200     0.044168\n",
      "17        34286    0.019506   503   0.028352     791     0.015880\n",
      "18        47971    0.027292   590   0.033256    2068     0.041518\n",
      "19        24023    0.013667   464   0.026154     606     0.012166\n",
      "20        48598    0.027649   699   0.039400    1174     0.023570\n",
      "21        66161    0.037641   778   0.043853    1949     0.039129\n",
      "22        46666    0.026550   919   0.051801    1206     0.024212\n",
      "23        15949    0.009074   465   0.026210     476     0.009556\n",
      "24        58246    0.033138   607   0.034215    1307     0.026240\n",
      "25        83336    0.047412   378   0.021307    2028     0.040715\n",
      "26        64613    0.036760  1153   0.064991    1653     0.033186\n",
      "27        77719    0.044217  1214   0.068429    1931     0.038767\n",
      "28        39964    0.022737   365   0.020574     868     0.017426\n",
      "29        61498    0.034988   346   0.019503    1620     0.032524\n"
     ]
    }
   ],
   "source": [
    "distribution_report = pd.DataFrame(range(0,clusters[0]), columns=['cluster'])\n",
    "distribution_report['train'] = df_train[[f'cluster_dtw_{clusters[0]}','periodo']].groupby(f'cluster_dtw_{clusters[0]}').count()\n",
    "distribution_report['train_prop'] = distribution_report['train'] / distribution_report['train'].sum()\n",
    "distribution_report['test'] = df_test[[f'cluster_dtw_{clusters[0]}','periodo']].groupby(f'cluster_dtw_{clusters[0]}').count()\n",
    "distribution_report['test_prop'] = distribution_report['test'] / distribution_report['test'].sum()\n",
    "distribution_report['futuro'] = df_futuro[[f'cluster_dtw_{clusters[0]}','periodo']].groupby(f'cluster_dtw_{clusters[0]}').count()\n",
    "distribution_report['futuro_prop'] = distribution_report['futuro'] / distribution_report['futuro'].sum()\n",
    "distribution_report.set_index('cluster', inplace=True)\n",
    "\n",
    "print(f\"DISTRIBUCION DE DATOS EN CLUSTERS:\\n{distribution_report.head(clusters[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertidas a categorical: ['yearquarter', 'cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df_train.select_dtypes(['category']).columns.tolist()\n",
    "for col in categorical_features:\n",
    "    df_train[col] = df_train[col].cat.codes\n",
    "    df_test[col] = df_test[col].cat.codes\n",
    "    df_futuro[col] = df_futuro[col].cat.codes\n",
    "print(f\"Convertidas a categorical: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertidas a Boolean: ['max_1', 'max_2', 'max_3', 'max_4', 'max_5', 'max_6', 'max_7', 'max_8', 'max_9', 'max_10', 'max_11', 'max_12', 'max_15', 'max_18', 'max_21', 'max_24', 'max_30', 'max_36', 'crece_2', 'crece_3', 'crece_4', 'crece_5', 'crece_6', 'crece_7', 'crece_8', 'crece_9', 'crece_10', 'crece_11', 'crece_12', 'decrece_2', 'decrece_3', 'decrece_4', 'decrece_5', 'decrece_6', 'decrece_7', 'decrece_8', 'decrece_9', 'decrece_10', 'decrece_11', 'decrece_12']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df_train.select_dtypes(['object']).columns.tolist()\n",
    "for col in categorical_features:\n",
    "    df_train[col] = df_train[col].astype('bool')\n",
    "    df_test[col] = df_test[col].astype('bool')\n",
    "    df_futuro[col] = df_futuro[col].astype('bool')\n",
    "print(f\"Convertidas a Boolean: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_cluster_ttf(df_train, df_test, df_futuro, cluster_col, cluster):\n",
    "    X_train = df_train[df_train[cluster_col] == cluster].iloc[:,:-1]\n",
    "    X_test = df_test[df_test[cluster_col] == cluster].iloc[:,:-1]\n",
    "    X_futuro = df_futuro[df_futuro[cluster_col] == cluster].iloc[:,:-1]\n",
    "\n",
    "    y_train = df_train[df_train[cluster_col] == cluster].iloc[:,-1]\n",
    "    y_test = df_test[df_test[cluster_col] == cluster].iloc[:,-1]\n",
    "    y_futuro = df_futuro[df_futuro[cluster_col] == cluster].iloc[:,-1]\n",
    "\n",
    "    print(f\"{'Cluster Column':.<25}: {cluster_col}\")\n",
    "    print(f\"{'Cluster':.<25}: {cluster}\")\n",
    "    print(f\"{'Shape X_train':.<25}: {X_train.shape}\")\n",
    "    print(f\"{'Shape X_test':.<25}: {X_test.shape}\")\n",
    "    print(f\"{'Shape X_futuro':.<25}: {X_futuro.shape}\")\n",
    "\n",
    "    print(f\"{'Shape y_train':.<25}: {y_train.shape}\")\n",
    "    print(f\"{'Shape y_test':.<25}: {y_test.shape}\")\n",
    "    print(f\"{'Shape y_futuro':.<25}: {y_futuro.shape}\")\n",
    "    print(f\"\\n\")\n",
    "\n",
    "    return X_train, X_test, X_futuro, y_train, y_test, y_futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster(X_train, X_test, X_futuro, y_train, y_test, y_futuro):\n",
    "\n",
    "    train_data = lgb.Dataset(X_train.drop(columns=exclusiones), label=y_train)\n",
    "    test_data = lgb.Dataset(X_test.drop(columns=exclusiones), label=y_test)\n",
    "    #futuro_data = lgb.Dataset(X_futuro.drop(columns=exclusiones), label=y_futuro)\n",
    "\n",
    "    params = lgbm_params\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=var_num_boost_round,\n",
    "                    valid_sets=[test_data, train_data],\n",
    "                    )\n",
    "\n",
    "    y_pred = model.predict(X_test.drop(columns=exclusiones), num_iteration=model.best_iteration)\n",
    "    y_pred_futuro = model.predict(X_futuro.drop(columns=exclusiones), num_iteration=model.best_iteration)\n",
    "\n",
    "    return model, y_pred, y_pred_futuro\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 0\n",
      "Shape X_train............: (35809, 189)\n",
      "Shape X_test.............: (212, 189)\n",
      "Shape X_futuro...........: (1107, 189)\n",
      "Shape y_train............: (35809,)\n",
      "Shape y_test.............: (212,)\n",
      "Shape y_futuro...........: (1107,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 75292\n",
      "[LightGBM] [Info] Number of data points in the train set: 35809, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score -0.134999\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[452]\ttraining's l2: 0.688927\ttraining's rmse: 0.830016\tvalid_0's l2: 0.748274\tvalid_0's rmse: 0.865028\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 1\n",
      "Shape X_train............: (51551, 189)\n",
      "Shape X_test.............: (951, 189)\n",
      "Shape X_futuro...........: (1360, 189)\n",
      "Shape y_train............: (51551,)\n",
      "Shape y_test.............: (951,)\n",
      "Shape y_futuro...........: (1360,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 102172\n",
      "[LightGBM] [Info] Number of data points in the train set: 51551, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -0.082342\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's l2: 0.69822\ttraining's rmse: 0.835596\tvalid_0's l2: 0.350944\tvalid_0's rmse: 0.592405\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 2\n",
      "Shape X_train............: (66039, 189)\n",
      "Shape X_test.............: (494, 189)\n",
      "Shape X_futuro...........: (1580, 189)\n",
      "Shape y_train............: (66039,)\n",
      "Shape y_test.............: (494,)\n",
      "Shape y_futuro...........: (1580,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 96618\n",
      "[LightGBM] [Info] Number of data points in the train set: 66039, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score -0.033513\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[651]\ttraining's l2: 0.773253\ttraining's rmse: 0.879348\tvalid_0's l2: 0.616115\tvalid_0's rmse: 0.78493\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 3\n",
      "Shape X_train............: (60514, 189)\n",
      "Shape X_test.............: (428, 189)\n",
      "Shape X_futuro...........: (3328, 189)\n",
      "Shape y_train............: (60514,)\n",
      "Shape y_test.............: (428,)\n",
      "Shape y_futuro...........: (3328,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 62121\n",
      "[LightGBM] [Info] Number of data points in the train set: 60514, number of used features: 138\n",
      "[LightGBM] [Info] Start training from score -0.321519\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[796]\ttraining's l2: 0.307891\ttraining's rmse: 0.554879\tvalid_0's l2: 0.506384\tvalid_0's rmse: 0.711606\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 4\n",
      "Shape X_train............: (66069, 189)\n",
      "Shape X_test.............: (652, 189)\n",
      "Shape X_futuro...........: (1488, 189)\n",
      "Shape y_train............: (66069,)\n",
      "Shape y_test.............: (652,)\n",
      "Shape y_futuro...........: (1488,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 101590\n",
      "[LightGBM] [Info] Number of data points in the train set: 66069, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 0.014045\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[708]\ttraining's l2: 0.759572\ttraining's rmse: 0.871534\tvalid_0's l2: 0.78\tvalid_0's rmse: 0.883176\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 5\n",
      "Shape X_train............: (54427, 189)\n",
      "Shape X_test.............: (654, 189)\n",
      "Shape X_futuro...........: (1354, 189)\n",
      "Shape y_train............: (54427,)\n",
      "Shape y_test.............: (654,)\n",
      "Shape y_futuro...........: (1354,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 101227\n",
      "[LightGBM] [Info] Number of data points in the train set: 54427, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -0.078557\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's l2: 0.695169\ttraining's rmse: 0.833768\tvalid_0's l2: 0.864394\tvalid_0's rmse: 0.929728\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 6\n",
      "Shape X_train............: (58743, 189)\n",
      "Shape X_test.............: (381, 189)\n",
      "Shape X_futuro...........: (1425, 189)\n",
      "Shape y_train............: (58743,)\n",
      "Shape y_test.............: (381,)\n",
      "Shape y_futuro...........: (1425,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 95516\n",
      "[LightGBM] [Info] Number of data points in the train set: 58743, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score -0.078317\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[666]\ttraining's l2: 0.780716\ttraining's rmse: 0.883581\tvalid_0's l2: 0.793069\tvalid_0's rmse: 0.890544\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 7\n",
      "Shape X_train............: (75021, 189)\n",
      "Shape X_test.............: (303, 189)\n",
      "Shape X_futuro...........: (1738, 189)\n",
      "Shape y_train............: (75021,)\n",
      "Shape y_test.............: (303,)\n",
      "Shape y_futuro...........: (1738,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 90426\n",
      "[LightGBM] [Info] Number of data points in the train set: 75021, number of used features: 163\n",
      "[LightGBM] [Info] Start training from score 0.047051\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[775]\ttraining's l2: 0.760803\ttraining's rmse: 0.87224\tvalid_0's l2: 0.861869\tvalid_0's rmse: 0.928369\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 8\n",
      "Shape X_train............: (48484, 189)\n",
      "Shape X_test.............: (979, 189)\n",
      "Shape X_futuro...........: (1318, 189)\n",
      "Shape y_train............: (48484,)\n",
      "Shape y_test.............: (979,)\n",
      "Shape y_futuro...........: (1318,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 102633\n",
      "[LightGBM] [Info] Number of data points in the train set: 48484, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -0.081892\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttraining's l2: 0.749736\ttraining's rmse: 0.865873\tvalid_0's l2: 0.687563\tvalid_0's rmse: 0.829194\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 9\n",
      "Shape X_train............: (50936, 189)\n",
      "Shape X_test.............: (385, 189)\n",
      "Shape X_futuro...........: (2242, 189)\n",
      "Shape y_train............: (50936,)\n",
      "Shape y_test.............: (385,)\n",
      "Shape y_futuro...........: (2242,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 70050\n",
      "[LightGBM] [Info] Number of data points in the train set: 50936, number of used features: 144\n",
      "[LightGBM] [Info] Start training from score 0.266489\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[776]\ttraining's l2: 0.410014\ttraining's rmse: 0.640323\tvalid_0's l2: 0.530638\tvalid_0's rmse: 0.728449\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 10\n",
      "Shape X_train............: (49795, 189)\n",
      "Shape X_test.............: (505, 189)\n",
      "Shape X_futuro...........: (1094, 189)\n",
      "Shape y_train............: (49795,)\n",
      "Shape y_test.............: (505,)\n",
      "Shape y_futuro...........: (1094,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 100174\n",
      "[LightGBM] [Info] Number of data points in the train set: 49795, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score 0.064038\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[694]\ttraining's l2: 0.801384\ttraining's rmse: 0.895201\tvalid_0's l2: 0.9937\tvalid_0's rmse: 0.996845\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 11\n",
      "Shape X_train............: (58565, 189)\n",
      "Shape X_test.............: (298, 189)\n",
      "Shape X_futuro...........: (1331, 189)\n",
      "Shape y_train............: (58565,)\n",
      "Shape y_test.............: (298,)\n",
      "Shape y_futuro...........: (1331,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 91098\n",
      "[LightGBM] [Info] Number of data points in the train set: 58565, number of used features: 159\n",
      "[LightGBM] [Info] Start training from score 0.087348\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttraining's l2: 0.703313\ttraining's rmse: 0.838637\tvalid_0's l2: 0.712795\tvalid_0's rmse: 0.844272\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 12\n",
      "Shape X_train............: (107370, 189)\n",
      "Shape X_test.............: (793, 189)\n",
      "Shape X_futuro...........: (4725, 189)\n",
      "Shape y_train............: (107370,)\n",
      "Shape y_test.............: (793,)\n",
      "Shape y_futuro...........: (4725,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 75942\n",
      "[LightGBM] [Info] Number of data points in the train set: 107370, number of used features: 150\n",
      "[LightGBM] [Info] Start training from score 0.155615\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[829]\ttraining's l2: 0.594762\ttraining's rmse: 0.771208\tvalid_0's l2: 0.669266\tvalid_0's rmse: 0.818087\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 13\n",
      "Shape X_train............: (81302, 189)\n",
      "Shape X_test.............: (571, 189)\n",
      "Shape X_futuro...........: (2332, 189)\n",
      "Shape y_train............: (81302,)\n",
      "Shape y_test.............: (571,)\n",
      "Shape y_futuro...........: (2332,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 91042\n",
      "[LightGBM] [Info] Number of data points in the train set: 81302, number of used features: 160\n",
      "[LightGBM] [Info] Start training from score -0.168186\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[759]\ttraining's l2: 0.616439\ttraining's rmse: 0.785137\tvalid_0's l2: 0.411363\tvalid_0's rmse: 0.641376\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 14\n",
      "Shape X_train............: (59480, 189)\n",
      "Shape X_test.............: (723, 189)\n",
      "Shape X_futuro...........: (1461, 189)\n",
      "Shape y_train............: (59480,)\n",
      "Shape y_test.............: (723,)\n",
      "Shape y_futuro...........: (1461,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 101672\n",
      "[LightGBM] [Info] Number of data points in the train set: 59480, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -0.051134\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\ttraining's l2: 0.778002\ttraining's rmse: 0.882044\tvalid_0's l2: 0.415139\tvalid_0's rmse: 0.644313\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 15\n",
      "Shape X_train............: (82259, 189)\n",
      "Shape X_test.............: (553, 189)\n",
      "Shape X_futuro...........: (2050, 189)\n",
      "Shape y_train............: (82259,)\n",
      "Shape y_test.............: (553,)\n",
      "Shape y_futuro...........: (2050,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 98199\n",
      "[LightGBM] [Info] Number of data points in the train set: 82259, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score 0.022271\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[981]\ttraining's l2: 0.752876\ttraining's rmse: 0.867684\tvalid_0's l2: 0.765598\tvalid_0's rmse: 0.874985\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 16\n",
      "Shape X_train............: (82286, 189)\n",
      "Shape X_test.............: (378, 189)\n",
      "Shape X_futuro...........: (2200, 189)\n",
      "Shape y_train............: (82286,)\n",
      "Shape y_test.............: (378,)\n",
      "Shape y_futuro...........: (2200,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 86954\n",
      "[LightGBM] [Info] Number of data points in the train set: 82286, number of used features: 158\n",
      "[LightGBM] [Info] Start training from score 0.082199\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[877]\ttraining's l2: 0.733912\ttraining's rmse: 0.856687\tvalid_0's l2: 0.953808\tvalid_0's rmse: 0.976631\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 17\n",
      "Shape X_train............: (34286, 189)\n",
      "Shape X_test.............: (503, 189)\n",
      "Shape X_futuro...........: (791, 189)\n",
      "Shape y_train............: (34286,)\n",
      "Shape y_test.............: (503,)\n",
      "Shape y_futuro...........: (791,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 100992\n",
      "[LightGBM] [Info] Number of data points in the train set: 34286, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 0.058642\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's l2: 0.808547\ttraining's rmse: 0.899192\tvalid_0's l2: 1.43281\tvalid_0's rmse: 1.197\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 18\n",
      "Shape X_train............: (47971, 189)\n",
      "Shape X_test.............: (590, 189)\n",
      "Shape X_futuro...........: (2068, 189)\n",
      "Shape y_train............: (47971,)\n",
      "Shape y_test.............: (590,)\n",
      "Shape y_futuro...........: (2068,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 78968\n",
      "[LightGBM] [Info] Number of data points in the train set: 47971, number of used features: 157\n",
      "[LightGBM] [Info] Start training from score -0.429521\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's l2: 0.186005\ttraining's rmse: 0.431283\tvalid_0's l2: 0.212976\tvalid_0's rmse: 0.461494\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 19\n",
      "Shape X_train............: (24023, 189)\n",
      "Shape X_test.............: (464, 189)\n",
      "Shape X_futuro...........: (606, 189)\n",
      "Shape y_train............: (24023,)\n",
      "Shape y_test.............: (464,)\n",
      "Shape y_futuro...........: (606,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 100033\n",
      "[LightGBM] [Info] Number of data points in the train set: 24023, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 0.042889\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[578]\ttraining's l2: 0.768761\ttraining's rmse: 0.87679\tvalid_0's l2: 1.21948\tvalid_0's rmse: 1.1043\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 20\n",
      "Shape X_train............: (48598, 189)\n",
      "Shape X_test.............: (699, 189)\n",
      "Shape X_futuro...........: (1174, 189)\n",
      "Shape y_train............: (48598,)\n",
      "Shape y_test.............: (699,)\n",
      "Shape y_futuro...........: (1174,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 101792\n",
      "[LightGBM] [Info] Number of data points in the train set: 48598, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 0.009340\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[626]\ttraining's l2: 0.800888\ttraining's rmse: 0.894923\tvalid_0's l2: 0.555275\tvalid_0's rmse: 0.745168\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 21\n",
      "Shape X_train............: (66161, 189)\n",
      "Shape X_test.............: (778, 189)\n",
      "Shape X_futuro...........: (1949, 189)\n",
      "Shape y_train............: (66161,)\n",
      "Shape y_test.............: (778,)\n",
      "Shape y_futuro...........: (1949,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 99163\n",
      "[LightGBM] [Info] Number of data points in the train set: 66161, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score -0.226901\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\ttraining's l2: 0.357943\ttraining's rmse: 0.598283\tvalid_0's l2: 0.349323\tvalid_0's rmse: 0.591035\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 22\n",
      "Shape X_train............: (46666, 189)\n",
      "Shape X_test.............: (919, 189)\n",
      "Shape X_futuro...........: (1206, 189)\n",
      "Shape y_train............: (46666,)\n",
      "Shape y_test.............: (919,)\n",
      "Shape y_futuro...........: (1206,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 102251\n",
      "[LightGBM] [Info] Number of data points in the train set: 46666, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -0.000837\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[603]\ttraining's l2: 0.82369\ttraining's rmse: 0.907573\tvalid_0's l2: 0.57996\tvalid_0's rmse: 0.761551\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 23\n",
      "Shape X_train............: (15949, 189)\n",
      "Shape X_test.............: (465, 189)\n",
      "Shape X_futuro...........: (476, 189)\n",
      "Shape y_train............: (15949,)\n",
      "Shape y_test.............: (465,)\n",
      "Shape y_futuro...........: (476,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 100115\n",
      "[LightGBM] [Info] Number of data points in the train set: 15949, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -0.009224\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's l2: 0.903523\ttraining's rmse: 0.950538\tvalid_0's l2: 1.45956\tvalid_0's rmse: 1.20812\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 24\n",
      "Shape X_train............: (58246, 189)\n",
      "Shape X_test.............: (607, 189)\n",
      "Shape X_futuro...........: (1307, 189)\n",
      "Shape y_train............: (58246,)\n",
      "Shape y_test.............: (607,)\n",
      "Shape y_futuro...........: (1307,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 101953\n",
      "[LightGBM] [Info] Number of data points in the train set: 58246, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 0.088478\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's l2: 0.748908\ttraining's rmse: 0.865394\tvalid_0's l2: 2.04168\tvalid_0's rmse: 1.42887\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 25\n",
      "Shape X_train............: (83336, 189)\n",
      "Shape X_test.............: (378, 189)\n",
      "Shape X_futuro...........: (2028, 189)\n",
      "Shape y_train............: (83336,)\n",
      "Shape y_test.............: (378,)\n",
      "Shape y_futuro...........: (2028,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 90352\n",
      "[LightGBM] [Info] Number of data points in the train set: 83336, number of used features: 158\n",
      "[LightGBM] [Info] Start training from score 0.110878\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[911]\ttraining's l2: 0.78537\ttraining's rmse: 0.886211\tvalid_0's l2: 1.12013\tvalid_0's rmse: 1.05836\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 26\n",
      "Shape X_train............: (64613, 189)\n",
      "Shape X_test.............: (1153, 189)\n",
      "Shape X_futuro...........: (1653, 189)\n",
      "Shape y_train............: (64613,)\n",
      "Shape y_test.............: (1153,)\n",
      "Shape y_futuro...........: (1653,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 103201\n",
      "[LightGBM] [Info] Number of data points in the train set: 64613, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -0.003811\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[625]\ttraining's l2: 0.84779\ttraining's rmse: 0.920755\tvalid_0's l2: 1.15033\tvalid_0's rmse: 1.07253\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 27\n",
      "Shape X_train............: (77719, 189)\n",
      "Shape X_test.............: (1214, 189)\n",
      "Shape X_futuro...........: (1931, 189)\n",
      "Shape y_train............: (77719,)\n",
      "Shape y_test.............: (1214,)\n",
      "Shape y_futuro...........: (1931,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 102736\n",
      "[LightGBM] [Info] Number of data points in the train set: 77719, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -0.017786\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\ttraining's l2: 0.897721\ttraining's rmse: 0.947481\tvalid_0's l2: 0.573143\tvalid_0's rmse: 0.757062\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 28\n",
      "Shape X_train............: (39964, 189)\n",
      "Shape X_test.............: (365, 189)\n",
      "Shape X_futuro...........: (868, 189)\n",
      "Shape y_train............: (39964,)\n",
      "Shape y_test.............: (365,)\n",
      "Shape y_futuro...........: (868,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 99147\n",
      "[LightGBM] [Info] Number of data points in the train set: 39964, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score 0.053340\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[768]\ttraining's l2: 0.774722\ttraining's rmse: 0.880183\tvalid_0's l2: 0.839065\tvalid_0's rmse: 0.916005\n",
      "Cluster Column...........: cluster_dtw_30\n",
      "Cluster..................: 29\n",
      "Shape X_train............: (61498, 189)\n",
      "Shape X_test.............: (346, 189)\n",
      "Shape X_futuro...........: (1620, 189)\n",
      "Shape y_train............: (61498,)\n",
      "Shape y_test.............: (346,)\n",
      "Shape y_futuro...........: (1620,)\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Total Bins 90648\n",
      "[LightGBM] [Info] Number of data points in the train set: 61498, number of used features: 160\n",
      "[LightGBM] [Info] Start training from score -0.168713\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[364]\ttraining's l2: 0.62219\ttraining's rmse: 0.78879\tvalid_0's l2: 0.391018\tvalid_0's rmse: 0.625314\n"
     ]
    }
   ],
   "source": [
    "modelos = []\n",
    "pred_final = pd.DataFrame()\n",
    "pred_final_futuro = pd.DataFrame()\n",
    "\n",
    "for cluster in range(0,clusters[0]):\n",
    "    X_train, X_test, X_futuro, y_train, y_test, y_futuro = separar_cluster_ttf(df_train, df_test, df_futuro, f'cluster_dtw_{clusters[0]}', cluster)\n",
    "    model, y_pred, y_pred_futuro = train_cluster(X_train, X_test, X_futuro, y_train, y_test, y_futuro)\n",
    "\n",
    "    modelos.append(model)\n",
    "\n",
    "    pred = X_test[['periodo','product_id','customer_id','tn_norm']]\n",
    "    pred['cluster'] = cluster\n",
    "    pred['tn_futuro'] = y_test\n",
    "    pred['tn_prediccion'] = y_pred\n",
    "    pred_final = pd.concat([pred_final, pred], ignore_index=True, axis=0)\n",
    "\n",
    "    pred_futuro =X_futuro[['periodo','product_id','customer_id','tn_norm']]\n",
    "    pred_futuro['cluster'] = cluster\n",
    "    pred_futuro['tn_futuro'] = y_futuro\n",
    "    pred_futuro['tn_prediccion'] = y_pred_futuro\n",
    "    pred_final_futuro = pd.concat([pred_final_futuro, pred_futuro], ignore_index=True, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pred_final.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "final['tn_futuro_real'] = (final['tn_norm'] + final['tn_futuro']) * final['std_dev_tn'] + final['average_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "final['tn_prediccion_real'] = (final['tn_norm'] + final['tn_prediccion']) * final['std_dev_tn'] + final['average_tn']\n",
    "final.to_parquet(f'{folder}/{path_pred_test}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_futuro = pred_final_futuro.merge(prod_stats, how='left', on=['product_id','customer_id'])\n",
    "final_futuro['tn_futuro_real'] = (final_futuro['tn_norm'] + final_futuro['tn_futuro']) * final_futuro['std_dev_tn'] + final_futuro['average_tn'] # por dos porque esta normalizado y al hacer sumas y restas se acumulan medias\n",
    "final_futuro['tn_prediccion_real'] = (final_futuro['tn_norm'] + final_futuro['tn_prediccion']) * final_futuro['std_dev_tn'] + final_futuro['average_tn']\n",
    "final_futuro.to_parquet(f'{folder}/{path_pred_futuro}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estado_control = f\"05_lightgbm Terminado - {nombrefile} - {datetime.now()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb.plot_importance(model, max_num_features=20, figsize=(10,10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_df = (\n",
    "#     pd.DataFrame({\n",
    "#         'feature_name': model.feature_name(),\n",
    "#         'importance_gain': model.feature_importance(importance_type='gain'),\n",
    "#         'importance_split': model.feature_importance(importance_type='split'),\n",
    "#     })\n",
    "#     .sort_values('importance_gain', ascending=False)\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "# importance_df.sort_values('importance_split', ascending=False, inplace=True)\n",
    "# feat_dibujar = importance_df[0:20]['feature_name'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dibujar_pesos==True:\n",
    "    fig, axs = plt.subplots(5, 4, figsize=(20, 25))\n",
    "    d = -1\n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            d+=1\n",
    "            lgb.plot_split_value_histogram(model,\n",
    "                            feature=feat_dibujar[d],\n",
    "                            bins=\"auto\",\n",
    "                            ax=axs[j, i]\n",
    "                            ,title=f\"Feat: {feat_dibujar[d]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------05_lightgbm (un intento)--------------------------------------\n",
      "----------------------------------------------FINALIZA----------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{fase:-^100}\")\n",
    "print(f\"{'FINALIZA':-^100}\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
